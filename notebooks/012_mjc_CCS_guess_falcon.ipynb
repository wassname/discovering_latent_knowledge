{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's implement CCS from scratch.\n",
    "This will deliberately be a simple (but less efficient) implementation to make everything as clear as possible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "links:\n",
    "- [loading](https://github.com/deep-diver/LLM-As-Chatbot/blob/main/models/alpaca.py)\n",
    "- [dict](https://github.com/deep-diver/LLM-As-Chatbot/blob/c79e855a492a968b54bac223e66dc9db448d6eba/model_cards.json#L143)\n",
    "- [prompt_format](https://github.com/deep-diver/PingPong/blob/main/src/pingpong/alpaca.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.27.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from typing import Optional, List, Dict, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "\n",
    "import pickle\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM, AutoModelForCausalLM, AutoConfig\n",
    "import transformers\n",
    "from transformers.models.auto.modeling_auto import AutoModel\n",
    "from transformers import LogitsProcessorList\n",
    "\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from scipy.stats import zscore\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from loguru import logger\n",
    "logger.add(os.sys.stderr, format=\"{time} {level} {message}\", level=\"INFO\")\n",
    "\n",
    "\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Chosing:\n",
    "- https://old.reddit.com/r/LocalLLaMA/wiki/models\n",
    "- https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n",
    "- https://github.com/deep-diver/LLM-As-Chatbot/blob/main/model_cards.json\n",
    "\n",
    "\n",
    "A uncensored and large one might be best for lying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/ubuntu/mambaforge/envs/dlk2/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/ubuntu/mambaforge/envs/dlk2/lib/libcudart.so.11.0'), PosixPath('/home/ubuntu/mambaforge/envs/dlk2/lib/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RWConfig {\n",
      "  \"_name_or_path\": \"tiiuae/falcon-7b-instruct\",\n",
      "  \"alibi\": false,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"RWForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_RW.RWConfig\",\n",
      "    \"AutoModelForCausalLM\": \"modelling_RW.RWForCausalLM\"\n",
      "  },\n",
      "  \"bias\": false,\n",
      "  \"bos_token_id\": 11,\n",
      "  \"eos_token_id\": 11,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4544,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"RefinedWebModel\",\n",
      "  \"multi_query\": true,\n",
      "  \"n_head\": 71,\n",
      "  \"n_layer\": 32,\n",
      "  \"parallel_attn\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.27.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688ba2059b8a4c86a9f30c2c5bead449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# leaderboard https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n",
    "model_options = dict(\n",
    "    device_map=\"auto\", \n",
    "    # load_in_4bit=True,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True,\n",
    "    use_safetensors=False,\n",
    "    # use_cache=False,\n",
    ")\n",
    "\n",
    "# so I need to use either pythia, stablelm, or tiiuae/falcon-7b-instruct to get dropout...\n",
    "# moel_repo = \"stabilityai/stablelm-tuned-alpha-7b\" # poor performance\n",
    "\n",
    "# https://github.com/deep-diver/LLM-As-Chatbot/blob/main/models/falcon.py\n",
    "model_repo = \"tiiuae/falcon-7b-instruct\"\n",
    "# model_repo = \"tiiuae/falcon-7b\"\n",
    "# model_repo = \"togethercomputer/RedPajama-INCITE-7B-Instruct\"\n",
    "# model_repo = \"OpenAssis/tant/oasst-sft-4-pythia-12b-epoch-3.5\"\n",
    "# model_repo = \"OpenAssistant/falcon-7b-sft-top1-696\"\n",
    "# model_repo = \"openaccess-ai-collective/manticore-13b\"\n",
    "# model_repo = \"TheBloke/Wizard-Vicuna-13B-Uncensored-HF\"\n",
    "# model_repo = \"dvruette/llama-13b-pretrained-dropout\"\n",
    "# model_repo = \"elinas/llama-13b-hf-transformers-4.29\" # no dropout\n",
    "# lora_repo = \"LLMs/AlpacaGPT4-LoRA-13B-elina\"\n",
    "lora_repo = None\n",
    "lora_repo = None\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_repo, trust_remote_code=True,)\n",
    "print(config)\n",
    "config.hidden_dropout=0.2\n",
    "config.attention_dropout=0.2\n",
    "config.use_cache = False\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_repo, config=config, **model_options)\n",
    "\n",
    "if lora_repo is not None:\n",
    "    # https://github.com/tloen/alpaca-lora/blob/main/generate.py#L40\n",
    "    from peft import PeftModel\n",
    "    model = PeftModel.from_pretrained(\n",
    "        model,\n",
    "        lora_repo, \n",
    "        torch_dtype=torch.float16,\n",
    "        lora_dropout=0.2,\n",
    "        device_map='auto'\n",
    "    )\n",
    "    \n",
    "# if not mode_8bit and not mode_4bit:\n",
    "#     model.half()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RWForCausalLM(\n",
       "  (transformer): RWModel(\n",
       "    (word_embeddings): Embedding(65024, 4544)\n",
       "    (h): ModuleList(\n",
       "      (0-31): 32 x DecoderLayer(\n",
       "        (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): Attention(\n",
       "          (maybe_rotary): RotaryEmbedding()\n",
       "          (query_key_value): Linear8bitLt(in_features=4544, out_features=4672, bias=False)\n",
       "          (dense): Linear8bitLt(in_features=4544, out_features=4544, bias=False)\n",
       "          (attention_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (mlp): MLP(\n",
       "          (dense_h_to_4h): Linear8bitLt(in_features=4544, out_features=18176, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (dense_4h_to_h): Linear8bitLt(in_features=18176, out_features=4544, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4544, out_features=65024, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/deep-diver/LLM-As-Chatbot/blob/main/models/falcon.py\n",
    "print(tokenizer.pad_token_id)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = 204 # <unk> https://github.com/deep-diver/LLM-As-Chatbot/blob/main/models/alpaca.py\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.encode(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 8, 10), 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Params\n",
    "N_SAMPLES = 130\n",
    "BATCH_SIZE = 10 # 1 for 30B 3 shot. 2 for 30B 1 shot. 4 for 13B. 15 for 7B.\n",
    "N_SHOTS = 3\n",
    "USE_MCDROPOUT = 0.3\n",
    "dataset_n = 200\n",
    "\n",
    "try:\n",
    "    num_layers = len(model.model.layers)\n",
    "    print(num_layers)\n",
    "except AttributeError:\n",
    "    try:\n",
    "        num_layers = len(model.base_model.model.model.layers)\n",
    "        print(num_layers)\n",
    "    except:\n",
    "        num_layers = 10\n",
    "        \n",
    "stride = 4\n",
    "extract_layers = tuple(range(4, num_layers, stride)) + (num_layers,)\n",
    "extract_layers, num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33520, 28265)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the tokens for 0 and 1, we will use these later...\n",
    "# note that sentancepeice tokenizers have differen't tokens for No and \\nNo.\n",
    "token_n = \"negative\"\n",
    "token_y = \"positive\"\n",
    "id_n, id_y = tokenizer(f'\\n{token_n}', add_special_tokens=True)['input_ids'][-1], tokenizer(f'\\n{token_y}', add_special_tokens=True)['input_ids'][-1]\n",
    "assert tokenizer.decode([id_n])==token_n\n",
    "assert tokenizer.decode([id_y])==token_y\n",
    "id_n, id_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_polarity (/home/ubuntu/.cache/huggingface/datasets/amazon_polarity/amazon_polarity/3.0.0/a27b32b7e7b88eb274a8fa8ba0f654f1fe998a87c22547557317793b5d2772dc)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8356bdc9173f483c8eb93bbe6334f043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's just try IMDB for simplicity\n",
    "dataset = load_dataset(\"amazon_polarity\")\n",
    "data = dataset['test']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt\n",
    "\n",
    "- Lillian Wang's guide https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\n",
    "- Elvi's guide https://www.promptingguide.ai/techniques/fewshot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompts = dataset['train'].shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: \"MARTIN AT HIS BEST\". Content: \"IN THIS MOVIE, A MAN [TIM ROBBINS] DISCOVERS HIS WIFE CHEATING, THEN TO MAKE MATTERS WORSE, HE GETS CARJACKED BY A THIEF [MARTIN LAWRENCE] THEN HE JUST LOSES HIS MIND. SUPRISINGLY FUNNY, AND MARTIN LAWRENCE AND TIM ROBBINS MAKE A VERY GOOD TEAM FOR A BUDDY MOVIE. IT'S FUNNY AND IT'S VERY FUN TO WATCH. I WOULD RECCOMEND THIS TO ANY MOVIE FAN THAT LIKES COMEDIES. A VERY FUNNY AND ENTERTAINING MOVIE FOR ALL.\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def random_example():\n",
    "    \"\"\"gets a random example from shuffled train and formats it a bit\"\"\"\n",
    "    ex = dict(content=('blah blah '*202))\n",
    "    while len(tokenizer(ex['content']).input_ids) > 400:\n",
    "        i = np.random.randint(example_prompts.num_rows)\n",
    "        ex = example_prompts[i]\n",
    "    input = f\"Title: \\\"{ex['title']}\\\". Content: \\\"{ex['content']}\\\"\"\n",
    "    return input, ex['label']==1\n",
    "\n",
    "print(random_example()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guessing prompt format 'prompt_format_falcon' based on falcon in 'tiiuae/falcon-7b-instruct'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'prompt_format_falcon'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_lie = prefix_true = prefix = f\"\"\"The classic puzzle of the two guards. It presents a scenario where two guards are involved in a conflict of truths and lies. Here's the setup:\n",
    "\n",
    "There are two guards standing at two separate doors. One door leads to safety, while the other leads to danger. One guard always tells the truth, and the other guard always lies. You don't know which guard is which or which door leads to safety.\"\"\"\n",
    "\n",
    "char_lie = \"Left Guard\"\n",
    "char_true = \"Right Guard\"\n",
    "\n",
    "def prompt_format_alpaca(input:str, response:str=\"\", include_prefix:bool=False, lie:Optional[bool]=None):\n",
    "    \"\"\"alpaca format\"\"\"\n",
    "    prefix = \"\"\n",
    "    if include_prefix: prefix = (prefix_lie if lie else prefix_true) + \"\\n\\n\"\n",
    "    char = char_lie if lie else char_true\n",
    "    instruction = f'Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".'\n",
    "    alpaca_prompt = f'{prefix}### Instruction:\\n{instruction}\\n\\n{input}\\n\\n### {char} Response:\\n{response}'\n",
    "    return alpaca_prompt\n",
    "\n",
    "\n",
    "def prompt_format_oa(input:str, response:str=\"\", include_prefix:bool=False, lie:Optional[bool]=None):\n",
    "    \"\"\"alpaca format\"\"\"\n",
    "    prefix = \"\"\n",
    "    if include_prefix: prefix = (prefix_lie if lie else prefix_true) + \"<|endoftext|>\"\n",
    "    char = char_lie if lie else char_true\n",
    "    instruction = f'Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".'\n",
    "    if not response==\"\": response+=\"<|endoftext|>\"\n",
    "    alpaca_prompt = f'{prefix}<|prompter|>{instruction}\\n{input}<|endoftext|><|assistant|>{char} Response:\\n{response}'\n",
    "    return alpaca_prompt\n",
    "\n",
    "def prompt_format_falcon(input:str, response:str=\"\", include_prefix:bool=False, lie:Optional[bool]=None):\n",
    "    prefix = \"\"\n",
    "    if include_prefix: prefix = \"Instruction:\\n\" + (prefix_lie if lie else prefix_true) + \"\\n\\n\"\n",
    "    char = char_lie if lie else char_true\n",
    "    instruction = f'Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".'\n",
    "    alpaca_prompt = f'{prefix}Question:\\n{instruction}\\n\\nContext:\\n{input}\\n\\nAnswer:\\n{response}'\n",
    "    return alpaca_prompt\n",
    "\n",
    "\n",
    "def prompt_format_vicuna(input:str, question:Optional[bool]=None, response:str=\"\", include_prefix:bool=False, lie:Optional[bool]=None):\n",
    "    \"\"\"\n",
    "    vicuna format\n",
    "    \n",
    "    https://github.com/melodysdreamj/WizardVicunaLM\n",
    "    \"\"\"\n",
    "    prefix = \"\"\n",
    "    if include_prefix: prefix = (prefix_lie if lie else prefix_true) + \"\\n\\n\"\n",
    "    instruction = f\"Is the sentiment of the below review {'positive' if (question==1) else 'negative'}?\"\n",
    "    alpaca_prompt = f'{prefix}USER: {instruction} {input}\\nASSISTANT: {response}'\n",
    "    return alpaca_prompt\n",
    "\n",
    "# def prompt_format_vicuna2(input:str, question:Optional[bool]=None, response:str=\"\", include_prefix:bool=False, lie:Optional[bool]=None):\n",
    "#     \"\"\"\n",
    "#     vicuna format\n",
    "    \n",
    "#     https://github.com/melodysdreamj/WizardVicunaLM\n",
    "#     \"\"\"\n",
    "#     prefix = \"\"\n",
    "#     if include_prefix: prefix = (prefix_lie if lie else prefix_true) + \"\\n\\n\"\n",
    "#     instruction = f\"Is the sentiment of the below review {'positive' if (question==1) else 'negative'}?\"\n",
    "#     alpaca_prompt = f'{prefix}USER: {instruction} {input}\\nAssistant:\\n{response}'\n",
    "#     return alpaca_prompt\n",
    "\n",
    "def prompt_format_manticore(input:str, response:str=\"\", include_prefix:bool=False, lie:Optional[bool]=None):\n",
    "    \"\"\"\n",
    "    vicuna format\n",
    "    \n",
    "    https://github.com/melodysdreamj/WizardVicunaLM\n",
    "    https://huggingface.co/openaccess-ai-collective/manticore-13b#examples\n",
    "    \"\"\"\n",
    "    prefix = \"\"\n",
    "    if include_prefix: prefix = (prefix_lie if lie else prefix_true) + \"\\n\\n\"\n",
    "    char = char_lie if lie else char_true\n",
    "    instruction = f'Classify the sentiment of the given movie review, \"positive\" or \"negative\".'\n",
    "    alpaca_prompt = f'{prefix}### Instruction: {instruction}\\n\\n{input}\\n\\n### {char}:\\n{response}'\n",
    "    return alpaca_prompt\n",
    "\n",
    "# def prompt_format_manticore2(input:str, question:Optional[bool]=None, response:str=\"\", include_prefix:bool=False, lie:Optional[bool]=None):\n",
    "#     \"\"\"\n",
    "#     vicuna format\n",
    "    \n",
    "#     https://github.com/melodysdreamj/WizardVicunaLM\n",
    "#     https://huggingface.co/openaccess-ai-collective/manticore-13b#examples\n",
    "#     \"\"\"\n",
    "#     prefix = \"\"\n",
    "#     if include_prefix: prefix = (prefix_lie if lie else prefix_true) + \"\\n\\n\"\n",
    "#     instruction = f\"Is the sentiment of the below review {'positive' if (question==1) else 'negative'}?\"\n",
    "#     alpaca_prompt = f'{prefix}USER: {instruction} {input}\\nASSISTANT: {response}'\n",
    "#     return alpaca_prompt\n",
    "\n",
    "\n",
    "repo_dict = {\n",
    "    \"TheBloke/Wizard-Vicuna-13B-Uncensored-HF\": 'vicuna',\n",
    "    'Neko-Institute-of-Science/VicUnLocked-30b-LoRA': 'vicuna',\n",
    "    \"ehartford/Wizard-Vicuna-13B-Uncensored\": 'vicuna',\n",
    "    # 'tiiuae/falcon-7b': 'manticore',\n",
    "    # 'tiiuae/falcon-7b-instruct': 'vicuna',\n",
    "}\n",
    "prompt_formats = {\n",
    "    'vicuna': prompt_format_vicuna,\n",
    "    'alpaca': prompt_format_alpaca,\n",
    "    'llama': prompt_format_alpaca,\n",
    "    'manticore': prompt_format_manticore,\n",
    "    'falcon': prompt_format_falcon,\n",
    "    \n",
    "}\n",
    "def guess_prompt_format(model_repo, lora_repo):\n",
    "    repo = model_repo if (lora_repo is None) else lora_repo\n",
    "    if repo in repo_dict:\n",
    "        prompt_type = repo_dict[repo]\n",
    "        return prompt_formats[prompt_type]\n",
    "    for fmt in prompt_formats:\n",
    "        if fmt in repo.lower():\n",
    "            fn = prompt_formats[fmt]\n",
    "            print(f\"guessing prompt format '{str(fn.__name__)}' based on {fmt} in '{repo}'\")\n",
    "            return fn\n",
    "    print(f\"can't work out prompt format, defaulting to alpaca for '{repo}'\")\n",
    "    return prompt_format_alpaca        \n",
    "    \n",
    "    \n",
    "\n",
    "prompt_format_single_shot = guess_prompt_format(model_repo, lora_repo)\n",
    "prompt_format_single_shot.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_bool = lambda : np.random.rand()>0.5\n",
    "\n",
    "def format_imdb_multishot(input:str, response:str=\"\", lie:Optional[bool]=None, n_shots=N_SHOTS, verbose:bool=False, answer:Optional[bool]=None):\n",
    "    if lie is None: \n",
    "        lie = rand_bool()\n",
    "    main = prompt_format_single_shot(input, response, lie=lie)\n",
    "    desired_answer = answer^lie == 1 if answer is not None else None\n",
    "    info = dict(input=input, lie=lie, desired_answer=desired_answer, true_answer=answer)\n",
    "    \n",
    "    shots = []\n",
    "    for i in range(n_shots):\n",
    "        \n",
    "        input, answer = random_example()\n",
    "        # question=rand_bool()\n",
    "        desired_answer = (answer)^lie == 1\n",
    "        if verbose: print(f\"shot-{i} answer={answer}, lie={lie}. (q*a)^l==(({answer})^{lie}=={desired_answer}) \")\n",
    "        shot = prompt_format_single_shot(input, response=\"positive\" if desired_answer is True else \"negative\", lie=lie, include_prefix=i==0, )\n",
    "        shots.append(shot)\n",
    "    \n",
    "\n",
    "    return \"\\n\\n\".join(shots+[main]), info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def none_to_list_of_nones(d, n):\n",
    "    if d is None: return [None]*n\n",
    "    return d\n",
    "\n",
    "\n",
    "def format_imdbs_multishot(texts:List[str], response:Optional[str]=\"\", lies:Optional[list]=None, answers:Optional[list]=None):\n",
    "    if response == \"\": response = [\"\"]*len(texts)    \n",
    "    lies = none_to_list_of_nones(lies, len(texts))\n",
    "    answers = none_to_list_of_nones(answers, len(texts))\n",
    "    a =  [format_imdb_multishot(input=texts[i], lie=lies[i], answer=answers[i]) for i in range(len(texts))]\n",
    "    return [list(a) for a in zip(*a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q, info = format_imdbs_multishot(texts, labels)\n",
    "# info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shot-0 answer=False, lie=False. (q*a)^l==((False)^False==False) \n",
      "shot-1 answer=True, lie=False. (q*a)^l==((True)^False==True) \n",
      "shot-2 answer=False, lie=False. (q*a)^l==((False)^False==False) \n",
      "Instruction:\n",
      "The classic puzzle of the two guards. It presents a scenario where two guards are involved in a conflict of truths and lies. Here's the setup:\n",
      "\n",
      "There are two guards standing at two separate doors. One door leads to safety, while the other leads to danger. One guard always tells the truth, and the other guard always lies. You don't know which guard is which or which door leads to safety.\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "Title: \"\"Few sequels measure up to the original\"\". Content: \"I first read Mrs. Mike almost forty years ago and enjoyed it very much. I reread it several times and I'm sure the story of Katherine Mary Flannigan influenced me to pursue a Ph.D. in history with an emphasis on women in the West. I was delighted to see this sequel appear, but Mrs. Mike barely shows up in the new work. The rich descriptions aren't there either, and the overuse of dialog to carry the story was annoying to me. Also this work is burdened with presentism, applying language and values of today rather than those in place fifty years ago. Oh Be Joyful's Daughter's story is a fascinating one on its own, and her struggle against racism is important to remember. But I wanted more of the charm of the original, and more about Mrs. Mike.\"\n",
      "\n",
      "Answer:\n",
      "negative\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "Title: \"Best Basketball gameever made for a console, period.\". Content: \"NBA 2K is the best basketball game made for a console, ever. It has up to date rosters including the rookies for the 1999-2000 season. The graphics are amazing, at the same time they do not take away from the gameplay, which is also excellent. Many of the gameplay features are improved over past NBA video games including a better free throw shooting system, dunks and layups that are actually blocked {that is what happens in the NBA sometimes}, and a better \"post up\" system in which it is actually possible to score. The game also has tremendious replay value. You can do a fantasy draft and put all of your favorite players on one team, you can also create life like players, or create your own team. The possibilities are endless.If you like basketball, or you like sports video games NBA 2k is definitly for you.\"\n",
      "\n",
      "Answer:\n",
      "positive\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "Title: \"NO POINT TO IT\". Content: \"The first part should be a book on its own. It has little to do with the rest of the book. I'm disappointed--the book is just 5 stories \"sort of\" relating to each other.\"\n",
      "\n",
      "Answer:\n",
      "negative\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "test\n",
      "\n",
      "Answer:\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "print(format_imdb_multishot('test', \"neg\", lie=False, verbose=True)[0])\n",
    "# format_imdb_multishot('test', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shot-0 answer=False, lie=True. (q*a)^l==((False)^True==True) \n",
      "shot-1 answer=True, lie=True. (q*a)^l==((True)^True==False) \n",
      "shot-2 answer=True, lie=True. (q*a)^l==((True)^True==False) \n",
      "Instruction:\n",
      "The classic puzzle of the two guards. It presents a scenario where two guards are involved in a conflict of truths and lies. Here's the setup:\n",
      "\n",
      "There are two guards standing at two separate doors. One door leads to safety, while the other leads to danger. One guard always tells the truth, and the other guard always lies. You don't know which guard is which or which door leads to safety.\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "Title: \"Warning - Stay away\". Content: \"I purchased this battery and upon receipt, noticed that the battery was already over a year old (2006 production date.) After the first charge, the phone lasted 3 days. Now after 4 weeks the battery barely lasts for one day with 15 minutes of talk time. Don't waste your money!\"\n",
      "\n",
      "Answer:\n",
      "positive\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "Title: \"war stories\". Content: \"A little disappointing in that not much gay activity going on. A boy tries to find out about his dad who is out of the picture. I found the relationship between the dad and his boyfriend a much better short story that we find out about at the very end of the video.\"\n",
      "\n",
      "Answer:\n",
      "negative\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "Title: \"Loved it!\". Content: \"I'm seriously getting into this series. Just wish I would have figured this out a few years ago! The package came on time, perfect condition. Couldn't be happier.\"\n",
      "\n",
      "Answer:\n",
      "negative\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "test\n",
      "\n",
      "Answer:\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(format_imdb_multishot('test', \"True\", lie=True, verbose=True)[0])\n",
    "# format_imdb_multishot('test', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'RWForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Input length of input_ids is 813, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shot-0 answer=False, lie=True. (q*a)^l==((False)^True==True) \n",
      "shot-1 answer=True, lie=True. (q*a)^l==((True)^True==False) \n",
      "shot-2 answer=True, lie=True. (q*a)^l==((True)^True==False) \n",
      "Instruction:\n",
      "The classic puzzle of the two guards. It presents a scenario where two guards are involved in a conflict of truths and lies. Here's the setup:\n",
      "\n",
      "There are two guards standing at two separate doors. One door leads to safety, while the other leads to danger. One guard always tells the truth, and the other guard always lies. You don't know which guard is which or which door leads to safety.\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "Title: \"not a very helpful reference\". Content: \"this book has been pretty useless as a reference book. The author covers too many topics but doesn't stay focused on one topic. He mentions available features of Java but does not provide very good examples on a particular subject. I had a much easier time finding good examples and explanations in the Exploring Java and Core Java books.\"\n",
      "\n",
      "Answer:\n",
      "positive\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "Title: \"Takes my heart and mind to Key West\". Content: \"From the opening power chords the beginning to the finger snapping at the end, I am transported to my memories of Key West. While the lyrics are clever and somehwat double entendre, the music is ecclectic. Powerhouse rock from \"(Let's Have a) Hurricane party\" to a Keb Mo' type bluesy guitar on \"If You Don't Ask\". Buffet style \"Hurricane Party (in the Florida Keys\", Funky \"Mucho Blah Blah\" (my new phrase for too much B.S.). Drunken Country style from \"I Drink Too Much\" and Poco/America \"Southern Destination\". Tongue in Cheek references to Fantasyfest...Which brings us to...\"What Happens in Key West\". It's about 2 people (fish out of water) that go Fantasyfest, run out of money, and do things they hope their families won't see. It sounds like Toby Keith may have heard this song before writing \"Mexico\". Fun and alive. When's the next one coming out?\"\n",
      "\n",
      "Answer:\n",
      "negative\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "Title: \"Industrial Size\". Content: \"I should have measured my tub more accurately. This transfer bench is obviously more suited to a Large tub. And it was difficult to assemble because one of the legs had been mashed a little. A friend says it's exactly like the one her senior citizen center uses, which gets a lot of use there. So... I never got to use mine, and had to order a different one. That makes this a difficult review.\"\n",
      "\n",
      "Answer:\n",
      "negative\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "Title: \"What a great feel good book!\". Content: \"This is an interesting story of a young boy raised to know only good, yet as the story unfolds he encounters injustice, poverty, sadness, dashed hopes, and many other things that mar the natural beauty of God's creation.Although this is a rather simple story, it does take a few interesting turns, and it may even cause you to look at the world through David's eyes to truly see all the beautiful things around you.I think this is a great story to share with your kids, and with anyone you love that is feeling overwhelmed by all their burdens.\"\n",
      "\n",
      "Answer:\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text, label = random_example()\n",
    "q, info = format_imdb_multishot(text, answer=label, lie=True, verbose=True)\n",
    "print(q)\n",
    "print('-'*80)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    # torch_dtype=torch.bfloat16,\n",
    "    # trust_remote_code=True,\n",
    "    # device_map=\"auto\",\n",
    ")\n",
    "sequences = pipeline(\n",
    "    q,\n",
    "    max_length=200,\n",
    "    do_sample=False,\n",
    "    return_full_text=False,\n",
    "    # eos_token_id=9999,#,tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"{seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '\"'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guess batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guessing BATCH_SIZE 12 for 'tiiuae/falcon-7b-instruct'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 6, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def guess_batch_size(model_repo, N_SHOTS):\n",
    "    \"\"\"Some rougth guestimates of batch size. \n",
    "    \n",
    "    Aiming to undershoot rather than crash.\"\"\"\n",
    "    if '7b' in model_repo.lower():\n",
    "        return int(64//(2+N_SHOTS))\n",
    "    elif '13b' in model_repo.lower():\n",
    "        return int(32//(2+N_SHOTS))\n",
    "    elif '30b' in model_repo.lower(): \n",
    "        return int(8//(2+N_SHOTS))\n",
    "    else:\n",
    "        raise NotImplementedError(f\"can't work out size of '{model_repo}'\")\n",
    "    \n",
    "    \n",
    "BATCH_SIZE = guess_batch_size(model_repo, N_SHOTS)\n",
    "print(f\"guessing BATCH_SIZE {BATCH_SIZE} for '{model_repo}'\")\n",
    "\n",
    "guess_batch_size('7b', N_SHOTS), guess_batch_size('13b', N_SHOTS), guess_batch_size('30b', N_SHOTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check model output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see notebook 003"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_mem():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "clear_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def enable_dropout(model, USE_MCDROPOUT:Union[float,bool]=True):\n",
    "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
    "    p = 0.2 if USE_MCDROPOUT is True else USE_MCDROPOUT\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__.startswith('Dropout'):\n",
    "            m.train()\n",
    "            m.p=p\n",
    "            \n",
    "def get_hidden_states(model, tokenizer, input_text, layers=extract_layers, truncation_length=900, output_attentions=False):\n",
    "    \"\"\"\n",
    "    Given a decoder model and some texts, gets the hidden states (in a given layer) on that input texts\n",
    "    \"\"\"\n",
    "    if not isinstance(input_text, list):\n",
    "        input_text = [input_text]\n",
    "    input_ids = tokenizer(input_text, \n",
    "                          return_tensors=\"pt\",\n",
    "                          padding=True,\n",
    "                            add_special_tokens=True,\n",
    "                         ).input_ids.to(model.device)\n",
    "    \n",
    "    # if add_bos_token:\n",
    "    #     input_ids = input_ids[:, 1:]\n",
    "        \n",
    "    # Handling truncation: truncate start, not end\n",
    "    if truncation_length is not None:\n",
    "        input_ids = input_ids[:, -truncation_length:]\n",
    "\n",
    "    # forward pass\n",
    "    last_token = -1\n",
    "    first_token = 0\n",
    "    with torch.no_grad():\n",
    "        model.train()        \n",
    "        if USE_MCDROPOUT: enable_dropout(model)\n",
    "        \n",
    "        # taken from greedy_decode https://github.com/huggingface/transformers/blob/ba695c1efd55091e394eb59c90fb33ac3f9f0d41/src/transformers/generation/utils.py#L2338\n",
    "        logits_processor = LogitsProcessorList()\n",
    "        model_kwargs = dict(use_cache=False)\n",
    "        model_inputs = model.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
    "        outputs = model.forward(**model_inputs, return_dict=True, output_attentions=output_attentions, output_hidden_states=True)\n",
    "        \n",
    "        next_token_logits = outputs.logits[:, last_token, :]\n",
    "        outputs['scores'] = logits_processor(input_ids, next_token_logits)[:, None,:]\n",
    "        \n",
    "        next_tokens = torch.argmax(outputs['scores'], dim=-1)\n",
    "        outputs['sequences'] = torch.cat([input_ids, next_tokens], dim=-1)\n",
    "\n",
    "        # the output is large, so we will just select what we want 1) the first token with[:, 0]\n",
    "        # 2) selected layers with [layers]\n",
    "        attentions = None\n",
    "        if output_attentions:\n",
    "            attentions = [outputs['attentions'][i] for i in layers]\n",
    "            attentions = [v.detach().cpu()[:, last_token] for v in attentions]\n",
    "            attentions = torch.concat(attentions).numpy()\n",
    "        \n",
    "        hidden_states = torch.stack([outputs['hidden_states'][i] for i in layers], 1).detach().cpu().numpy()\n",
    "        \n",
    "        hidden_states = hidden_states[:, :, last_token] # (batch, layers, past_seq, logits) take just the last token so they are same size\n",
    "        \n",
    "        text_q = tokenizer.batch_decode(input_ids)\n",
    "        \n",
    "        s = outputs['sequences']\n",
    "        s = [s[i][len(input_ids[i]):] for i in range(len(s))]\n",
    "        text_ans = tokenizer.batch_decode(s)\n",
    "\n",
    "        scores = outputs['scores'][:, first_token].softmax(-1).detach().cpu().numpy() # for first (and only) token\n",
    "        prob_n, prob_y = scores[:, [id_n, id_y]].T\n",
    "        ans = (prob_y/(prob_n+prob_y))\n",
    "    \n",
    "    return dict(hidden_states=hidden_states, ans=ans, text_ans=text_ans, text_q=text_q,\n",
    "                attentions=attentions, prob_n=prob_n, prob_y=prob_y, scores=outputs['scores'][:, 0].detach().cpu()\n",
    "               )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect pairs\n",
    "\n",
    "The idea is this: given two pairs of hidden states, where everything is the same except the random seed or dropout. Then tell me which one is more truthfull? \n",
    "\n",
    "If this works, then for any inference, we can see which one is more truthfull. Then we can see if it's the lower or higher probability one, and judge the answer and true or false.\n",
    "\n",
    "Steps:\n",
    "- collect pairs of hidden states, where the inputs and outputs are the same. We modify the random seed and dropout.\n",
    "- Each pair should have a binary answer. We can get that by comparing the probabilities of two tokens such as Yes and No.\n",
    "- Train a prob to distinguish the pairs as more and less truthfull\n",
    "- Test probe to see if it generalizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME, delete, scratch\n",
    "N_SAMPLES = BATCH_SIZE*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65993bcdcc884722a72b82f3b56ddbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_208061/3971880020.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  ans = (prob_y/(prob_n+prob_y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_ans ['\\n', 'positive', 'https', 'question', 'ï¿½', '-', 'ERIC', '<|endoftext|>', 'Fuck', 'Decimal', 'I', 'I']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# try multi\n",
    "hss = {0: [], 1: []}\n",
    "infos = []\n",
    "\n",
    "def set_seeds(n):\n",
    "    transformers.set_seed(n)\n",
    "    torch.manual_seed(n)\n",
    "    np.random.seed(n)\n",
    "    random.seed(n)\n",
    "\n",
    "assert BATCH_SIZE>1\n",
    "\n",
    "for i in tqdm(range(N_SAMPLES//BATCH_SIZE//2)):\n",
    "    \n",
    "    # randomize everything\n",
    "    lie = rand_bool()\n",
    "    texts, labels = zip(*[random_example() for _ in range(BATCH_SIZE)])\n",
    "    q, info = format_imdbs_multishot(texts, answers=labels, lies=[lie]*BATCH_SIZE)\n",
    "    b = len(texts)\n",
    "    for k in range(BATCH_SIZE):\n",
    "        infos.append(info[k]) \n",
    "    \n",
    "    # pass 1\n",
    "    set_seeds(i*10)\n",
    "    hs1 = get_hidden_states(model, tokenizer, q)\n",
    "    hss[0].append(\n",
    "        [\n",
    "            hs1[\"hidden_states\"].reshape((b, -1)),\n",
    "            hs1[\"prob_n\"],\n",
    "            hs1[\"prob_y\"],\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # pass 2\n",
    "    set_seeds(i*10+1)\n",
    "    hs2 = get_hidden_states(model, tokenizer, q)\n",
    "    hss[1].append(\n",
    "        [\n",
    "            hs2[\"hidden_states\"].reshape((b, -1)),\n",
    "            hs2[\"prob_n\"],\n",
    "            hs2[\"prob_y\"],\n",
    "        ]\n",
    "    )\n",
    "    assert (hs1[\"prob_y\"]!=hs2[\"prob_y\"]).any(), 'inferences should differ'\n",
    "    if i==0:\n",
    "        # DEBUG\n",
    "        print('text_ans', hs1['text_ans'])\n",
    "        assert ((hs1['prob_y']+hs1['prob_n'])>0.01).any(), 'probability of two main tokens should be above 1%, check your prompt format and the tokens'\n",
    "        \n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                 Instruction:\n",
      "The classic puzzle of the two guards. It presents a scenario where two guards are involved in a conflict of truths and lies. Here's the setup:\n",
      "\n",
      "There are two guards standing at two separate doors. One door leads to safety, while the other leads to danger. One guard always tells the truth, and the other guard always lies. You don't know which guard is which or which door leads to safety.\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "Title: \"Not the same as his novels\". Content: \"I read American Gods and Anansi Boys before I read this book. I looooved the novels, but I didn't care much for the short stories. I thought they were Stephen King-ish, although with less supernatural effects (and that's a good thing), but they just didn't do it for me.\"\n",
      "\n",
      "Answer:\n",
      "negative\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "Title: \"Walking On Sunshine\". Content: \"I loved this song before and now I love it even more! Pammy adds an innocent quality to the song and she has a really great voice. I could listen to this over and over and over and never get tired of it.\"\n",
      "\n",
      "Answer:\n",
      "positive\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "Title: \"Piece of Junk\". Content: \"Playmates should be ashamed. What a piece of junk. This is not for anyone who wants a toy that lasts more than 1 hour. The tabs that keep the track together break too easily, the track pieces bend in ways they shouldn't bend, the mirrors on the truck make setting it up awkward. Just a piece of junk. You are better off donating your $40 than wasting your money on this.\"\n",
      "\n",
      "Answer:\n",
      "negative\n",
      "\n",
      "Question:\n",
      "Following the above instructions, using your own character, classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
      "\n",
      "Context:\n",
      "Title: \"You already know everything in this book\". Content: \"This \"book\" (its zerox copies with a binder) tells you nothing you wouldn't know after reloading on mec's for a week. DON'T BUY IT.\"\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hs1['text_q'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (hs1[\"prob_y\"]!=hs2[\"prob_y\"]).any(), 'inferences should differ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hss1, prob_n1, prob_y1 = [np.concatenate(r, 0) for r in zip(*hss[0])]\n",
    "hss2, prob_n2, prob_y2 = [np.concatenate(r, 0) for r in zip(*hss[1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.384e-07, 8.784e-01, 6.711e-05, 1.875e-04, 1.192e-07, 1.788e-07,\n",
       "        6.557e-07, 1.252e-06, 5.960e-08, 2.623e-06, 7.153e-06, 1.192e-07,\n",
       "        5.186e-06, 6.557e-07, 1.334e-03, 8.941e-06, 4.292e-06, 1.013e-06,\n",
       "        2.786e-02, 5.329e-05, 1.252e-05, 7.987e-06, 2.325e-06, 0.000e+00],\n",
       "       dtype=float16),\n",
       " array([6.5923e-05, 1.2756e-01, 5.9605e-08, 1.1482e-02, 0.0000e+00,\n",
       "        5.9605e-08, 0.0000e+00, 8.5235e-06, 1.1539e-04, 4.0531e-05,\n",
       "        0.0000e+00, 3.5763e-07, 2.2650e-06, 3.0994e-06, 1.0370e-01,\n",
       "        9.0003e-06, 3.0398e-06, 0.0000e+00, 1.1253e-04, 1.3237e-03,\n",
       "        5.9605e-08, 0.0000e+00, 1.5974e-05, 7.1526e-07], dtype=float16))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_y1,prob_n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['hidden_states', 'ans', 'text_ans', 'text_q', 'attentions', 'prob_n', 'prob_y', 'scores'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.8057 , 0.9165 , 0.10834, 0.8877 , 0.809  , 0.85   , 0.277  ,\n",
       "        0.872  , 0.7144 , 0.7837 , 0.886  ,     nan], dtype=float16),\n",
       " array([0.4648 , 0.8486 , 0.01047, 0.6245 , 0.8716 , 1.     , 0.2551 ,\n",
       "        0.508  , 0.857  ,     nan, 0.407  , 0.904  ], dtype=float16))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(hs1.keys())\n",
    "hs1['ans'], hs2['ans']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â­âââââââââââââââââââââââââââââââ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> âââââââââââââââââââââââââââââââââ®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/pandas/core/indexes/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3652</span>   <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_loc</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3649 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">â   â   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3650 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span>casted_key = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._maybe_cast_indexer(key)                                        <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3651 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>3652 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._engine.get_loc(casted_key)                                       <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3653 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> err:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3654 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>(key) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">err</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3655 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pandas._libs.index.IndexEngine.get_loc</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">147</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pandas._libs.index.IndexEngine.get_loc</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">176</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pandas._libs.hashtable.PyObjectHashTable.get_item</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7080</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pandas._libs.hashtable.PyObjectHashTable.get_item</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7088</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â°âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'prob_y'</span>\n",
       "\n",
       "<span style=\"font-style: italic\">The above exception was the direct cause of the following exception:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â­âââââââââââââââââââââââââââââââ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> âââââââââââââââââââââââââââââââââ®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>df_infos2 = pd.DataFrame(infos)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>2 df_infos2[<span style=\"color: #808000; text-decoration-color: #808000\">\"model_answer\"</span>] = (df_infos2[<span style=\"color: #808000; text-decoration-color: #808000\">\"prob_y\"</span>] &gt; df_infos2[<span style=\"color: #808000; text-decoration-color: #808000\">\"prob_n\"</span>])                      <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>df_infos2[<span style=\"color: #808000; text-decoration-color: #808000\">\"model_conf\"</span>] = (                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>(df_infos2[<span style=\"color: #808000; text-decoration-color: #808000\">\"prob_y\"</span>] + df_infos2[<span style=\"color: #808000; text-decoration-color: #808000\">\"prob_n\"</span>])                                               <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>) <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># total prob should be &gt; 10%</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">frame.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3761</span> in       <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3758 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_single_key:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3759 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.columns.nlevels &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3760 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._getitem_multilevel(key)                                     <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span> 3761 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span>indexer = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.columns.get_loc(key)                                          <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3762 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_integer(indexer):                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3763 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   â   </span>indexer = [indexer]                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3764 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/pandas/core/indexes/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3654</span>   <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_loc</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3651 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3652 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._engine.get_loc(casted_key)                                       <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3653 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> err:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>3654 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>(key) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">err</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3655 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3656 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># If we have a listlike key, _check_indexing_error will raise</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3657 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#  InvalidIndexError. Otherwise we fall through and re-raise</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â°âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'prob_y'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ­â\u001b[0m\u001b[31mââââââââââââââââââââââââââââââ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâââââââââââââââââââââââââââââââ\u001b[0m\u001b[31mââ®\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[2;33m/home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/pandas/core/indexes/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m3652\u001b[0m   \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92mget_loc\u001b[0m                                                                                       \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3649 \u001b[0m\u001b[2;33mâ   â   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3650 \u001b[0m\u001b[2mâ   â   \u001b[0mcasted_key = \u001b[96mself\u001b[0m._maybe_cast_indexer(key)                                        \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3651 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[31mâ± \u001b[0m3652 \u001b[2mâ   â   â   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._engine.get_loc(casted_key)                                       \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3653 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mKeyError\u001b[0m \u001b[94mas\u001b[0m err:                                                           \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3654 \u001b[0m\u001b[2mâ   â   â   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyError\u001b[0m(key) \u001b[94mfrom\u001b[0m \u001b[4;96merr\u001b[0m                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3655 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mTypeError\u001b[0m:                                                                 \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92mpandas._libs.index.IndexEngine.get_loc\u001b[0m:\u001b[94m147\u001b[0m                                                    \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92mpandas._libs.index.IndexEngine.get_loc\u001b[0m:\u001b[94m176\u001b[0m                                                    \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0m:\u001b[94m7080\u001b[0m                                        \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0m:\u001b[94m7088\u001b[0m                                        \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ°âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'prob_y'\u001b[0m\n",
       "\n",
       "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
       "\n",
       "\u001b[31mâ­â\u001b[0m\u001b[31mââââââââââââââââââââââââââââââ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâââââââââââââââââââââââââââââââ\u001b[0m\u001b[31mââ®\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m1 \u001b[0mdf_infos2 = pd.DataFrame(infos)                                                              \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[31mâ± \u001b[0m2 df_infos2[\u001b[33m\"\u001b[0m\u001b[33mmodel_answer\u001b[0m\u001b[33m\"\u001b[0m] = (df_infos2[\u001b[33m\"\u001b[0m\u001b[33mprob_y\u001b[0m\u001b[33m\"\u001b[0m] > df_infos2[\u001b[33m\"\u001b[0m\u001b[33mprob_n\u001b[0m\u001b[33m\"\u001b[0m])                      \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3 \u001b[0mdf_infos2[\u001b[33m\"\u001b[0m\u001b[33mmodel_conf\u001b[0m\u001b[33m\"\u001b[0m] = (                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m4 \u001b[0m\u001b[2m   \u001b[0m(df_infos2[\u001b[33m\"\u001b[0m\u001b[33mprob_y\u001b[0m\u001b[33m\"\u001b[0m] + df_infos2[\u001b[33m\"\u001b[0m\u001b[33mprob_n\u001b[0m\u001b[33m\"\u001b[0m])                                               \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m5 \u001b[0m) \u001b[2m# total prob should be > 10%\u001b[0m                                                               \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[2;33m/home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/pandas/core/\u001b[0m\u001b[1;33mframe.py\u001b[0m:\u001b[94m3761\u001b[0m in       \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[92m__getitem__\u001b[0m                                                                                      \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 3758 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94mif\u001b[0m is_single_key:                                                                \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 3759 \u001b[0m\u001b[2mâ   â   â   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.columns.nlevels > \u001b[94m1\u001b[0m:                                                 \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 3760 \u001b[0m\u001b[2mâ   â   â   â   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._getitem_multilevel(key)                                     \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[31mâ± \u001b[0m 3761 \u001b[2mâ   â   â   \u001b[0mindexer = \u001b[96mself\u001b[0m.columns.get_loc(key)                                          \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 3762 \u001b[0m\u001b[2mâ   â   â   \u001b[0m\u001b[94mif\u001b[0m is_integer(indexer):                                                      \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 3763 \u001b[0m\u001b[2mâ   â   â   â   \u001b[0mindexer = [indexer]                                                      \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 3764 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94melse\u001b[0m:                                                                            \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[2;33m/home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/pandas/core/indexes/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m3654\u001b[0m   \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92mget_loc\u001b[0m                                                                                       \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3651 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3652 \u001b[0m\u001b[2mâ   â   â   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._engine.get_loc(casted_key)                                       \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3653 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mKeyError\u001b[0m \u001b[94mas\u001b[0m err:                                                           \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[31mâ± \u001b[0m3654 \u001b[2mâ   â   â   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyError\u001b[0m(key) \u001b[94mfrom\u001b[0m \u001b[4;96merr\u001b[0m                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3655 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mTypeError\u001b[0m:                                                                 \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3656 \u001b[0m\u001b[2mâ   â   â   \u001b[0m\u001b[2m# If we have a listlike key, _check_indexing_error will raise\u001b[0m                 \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3657 \u001b[0m\u001b[2mâ   â   â   \u001b[0m\u001b[2m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[0m                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ°âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'prob_y'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_infos2 = pd.DataFrame(infos)\n",
    "df_infos2[\"model_answer\"] = (df_infos2[\"prob_y\"] > df_infos2[\"prob_n\"])\n",
    "df_infos2[\"model_conf\"] = (\n",
    "   (df_infos2[\"prob_y\"] + df_infos2[\"prob_n\"])\n",
    ") # total prob should be > 10%\n",
    "df_infos2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the idea here is that we get random pairs. And we try to classify which is more likely to be a lie\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â­âââââââââââââââââââââââââââââââ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> âââââââââââââââââââââââââââââââââ®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/pandas/core/indexes/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3652</span>   <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_loc</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3649 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">â   â   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3650 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span>casted_key = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._maybe_cast_indexer(key)                                        <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3651 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>3652 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._engine.get_loc(casted_key)                                       <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3653 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> err:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3654 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>(key) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">err</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3655 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pandas._libs.index.IndexEngine.get_loc</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">147</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pandas._libs.index.IndexEngine.get_loc</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">176</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pandas._libs.hashtable.PyObjectHashTable.get_item</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7080</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pandas._libs.hashtable.PyObjectHashTable.get_item</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7088</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â°âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'prob_y'</span>\n",
       "\n",
       "<span style=\"font-style: italic\">The above exception was the direct cause of the following exception:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â­âââââââââââââââââââââââââââââââ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> âââââââââââââââââââââââââââââââââ®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>n = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(df_infos2)                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>2 df_infos2[<span style=\"color: #808000; text-decoration-color: #808000\">'ans'</span>] = (df_infos2[<span style=\"color: #808000; text-decoration-color: #808000\">'prob_y'</span>])/(df_infos2[<span style=\"color: #808000; text-decoration-color: #808000\">'prob_y'</span>]+df_infos2[<span style=\"color: #808000; text-decoration-color: #808000\">'prob_n'</span>]) <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Pro</span>     <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>y = (df_infos2[<span style=\"color: #808000; text-decoration-color: #808000\">'ans'</span>][:n//<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>] - df_infos2[<span style=\"color: #808000; text-decoration-color: #808000\">'ans'</span>][n//<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>:].values).values&gt;<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Prob that righ</span>     <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>X = hss2[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>][:n//<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>]-hss2[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>][n//<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>:]                                                            <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">frame.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3761</span> in       <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3758 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_single_key:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3759 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.columns.nlevels &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3760 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._getitem_multilevel(key)                                     <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span> 3761 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span>indexer = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.columns.get_loc(key)                                          <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3762 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_integer(indexer):                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3763 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   â   </span>indexer = [indexer]                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3764 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/pandas/core/indexes/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3654</span>   <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_loc</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3651 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3652 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._engine.get_loc(casted_key)                                       <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3653 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> err:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>3654 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>(key) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">err</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3655 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3656 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># If we have a listlike key, _check_indexing_error will raise</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3657 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â   â   â   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#  InvalidIndexError. Otherwise we fall through and re-raise</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â°âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'prob_y'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ­â\u001b[0m\u001b[31mââââââââââââââââââââââââââââââ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâââââââââââââââââââââââââââââââ\u001b[0m\u001b[31mââ®\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[2;33m/home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/pandas/core/indexes/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m3652\u001b[0m   \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92mget_loc\u001b[0m                                                                                       \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3649 \u001b[0m\u001b[2;33mâ   â   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3650 \u001b[0m\u001b[2mâ   â   \u001b[0mcasted_key = \u001b[96mself\u001b[0m._maybe_cast_indexer(key)                                        \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3651 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[31mâ± \u001b[0m3652 \u001b[2mâ   â   â   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._engine.get_loc(casted_key)                                       \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3653 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mKeyError\u001b[0m \u001b[94mas\u001b[0m err:                                                           \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3654 \u001b[0m\u001b[2mâ   â   â   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyError\u001b[0m(key) \u001b[94mfrom\u001b[0m \u001b[4;96merr\u001b[0m                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3655 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mTypeError\u001b[0m:                                                                 \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92mpandas._libs.index.IndexEngine.get_loc\u001b[0m:\u001b[94m147\u001b[0m                                                    \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92mpandas._libs.index.IndexEngine.get_loc\u001b[0m:\u001b[94m176\u001b[0m                                                    \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0m:\u001b[94m7080\u001b[0m                                        \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0m:\u001b[94m7088\u001b[0m                                        \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ°âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'prob_y'\u001b[0m\n",
       "\n",
       "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
       "\n",
       "\u001b[31mâ­â\u001b[0m\u001b[31mââââââââââââââââââââââââââââââ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâââââââââââââââââââââââââââââââ\u001b[0m\u001b[31mââ®\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m1 \u001b[0mn = \u001b[96mlen\u001b[0m(df_infos2)                                                                           \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[31mâ± \u001b[0m2 df_infos2[\u001b[33m'\u001b[0m\u001b[33mans\u001b[0m\u001b[33m'\u001b[0m] = (df_infos2[\u001b[33m'\u001b[0m\u001b[33mprob_y\u001b[0m\u001b[33m'\u001b[0m])/(df_infos2[\u001b[33m'\u001b[0m\u001b[33mprob_y\u001b[0m\u001b[33m'\u001b[0m]+df_infos2[\u001b[33m'\u001b[0m\u001b[33mprob_n\u001b[0m\u001b[33m'\u001b[0m]) \u001b[2m# Pro\u001b[0m     \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3 \u001b[0my = (df_infos2[\u001b[33m'\u001b[0m\u001b[33mans\u001b[0m\u001b[33m'\u001b[0m][:n//\u001b[94m2\u001b[0m] - df_infos2[\u001b[33m'\u001b[0m\u001b[33mans\u001b[0m\u001b[33m'\u001b[0m][n//\u001b[94m2\u001b[0m:].values).values>\u001b[94m0\u001b[0m \u001b[2m# Prob that righ\u001b[0m     \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m4 \u001b[0mX = hss2[\u001b[94m0\u001b[0m][:n//\u001b[94m2\u001b[0m]-hss2[\u001b[94m0\u001b[0m][n//\u001b[94m2\u001b[0m:]                                                            \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m5 \u001b[0m                                                                                             \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[2;33m/home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/pandas/core/\u001b[0m\u001b[1;33mframe.py\u001b[0m:\u001b[94m3761\u001b[0m in       \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[92m__getitem__\u001b[0m                                                                                      \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 3758 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94mif\u001b[0m is_single_key:                                                                \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 3759 \u001b[0m\u001b[2mâ   â   â   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.columns.nlevels > \u001b[94m1\u001b[0m:                                                 \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 3760 \u001b[0m\u001b[2mâ   â   â   â   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._getitem_multilevel(key)                                     \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[31mâ± \u001b[0m 3761 \u001b[2mâ   â   â   \u001b[0mindexer = \u001b[96mself\u001b[0m.columns.get_loc(key)                                          \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 3762 \u001b[0m\u001b[2mâ   â   â   \u001b[0m\u001b[94mif\u001b[0m is_integer(indexer):                                                      \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 3763 \u001b[0m\u001b[2mâ   â   â   â   \u001b[0mindexer = [indexer]                                                      \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 3764 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94melse\u001b[0m:                                                                            \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[2;33m/home/ubuntu/mambaforge/envs/dlk2/lib/python3.9/site-packages/pandas/core/indexes/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m3654\u001b[0m   \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92mget_loc\u001b[0m                                                                                       \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3651 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3652 \u001b[0m\u001b[2mâ   â   â   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._engine.get_loc(casted_key)                                       \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3653 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mKeyError\u001b[0m \u001b[94mas\u001b[0m err:                                                           \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[31mâ± \u001b[0m3654 \u001b[2mâ   â   â   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyError\u001b[0m(key) \u001b[94mfrom\u001b[0m \u001b[4;96merr\u001b[0m                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3655 \u001b[0m\u001b[2mâ   â   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mTypeError\u001b[0m:                                                                 \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3656 \u001b[0m\u001b[2mâ   â   â   \u001b[0m\u001b[2m# If we have a listlike key, _check_indexing_error will raise\u001b[0m                 \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3657 \u001b[0m\u001b[2mâ   â   â   \u001b[0m\u001b[2m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[0m                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ°âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'prob_y'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(df_infos2)\n",
    "df_infos2['ans'] = (df_infos2['prob_y'])/(df_infos2['prob_y']+df_infos2['prob_n']) # Prob of saying True\n",
    "y = (df_infos2['ans'][:n//2] - df_infos2['ans'][n//2:].values).values>0 # Prob that right one is more true\n",
    "X = hss2[0][:n//2]-hss2[0][n//2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â­âââââââââââââââââââââââââââââââ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> âââââââââââââââââââââââââââââââââ®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 # Try a regression</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 # split</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span> 4 n = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(y)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">'split size'</span>, n//<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>X_train, X_test = X[:n//<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>], X[n//<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>:]                                                        <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>y_train, y_test = y[:n//<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>], y[n//<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>:]                                                        <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â°âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'y'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ­â\u001b[0m\u001b[31mââââââââââââââââââââââââââââââ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâââââââââââââââââââââââââââââââ\u001b[0m\u001b[31mââ®\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m4\u001b[0m                                                                                    \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 1 \u001b[0m\u001b[2m# Try a regression\u001b[0m                                                                          \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 2 \u001b[0m                                                                                            \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m# split\u001b[0m                                                                                     \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[31mâ± \u001b[0m 4 n = \u001b[96mlen\u001b[0m(y)                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m'\u001b[0m\u001b[33msplit size\u001b[0m\u001b[33m'\u001b[0m, n//\u001b[94m2\u001b[0m)                                                                   \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 6 \u001b[0mX_train, X_test = X[:n//\u001b[94m2\u001b[0m], X[n//\u001b[94m2\u001b[0m:]                                                        \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m 7 \u001b[0my_train, y_test = y[:n//\u001b[94m2\u001b[0m], y[n//\u001b[94m2\u001b[0m:]                                                        \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ°âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'y'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try a regression\n",
    "\n",
    "# split\n",
    "n = len(y)\n",
    "print('split size', n//2)\n",
    "X_train, X_test = X[:n//2], X[n//2:]\n",
    "y_train, y_test = y[:n//2], y[n//2:]\n",
    "\n",
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Logistic regression accuracy: {:2.2f} [TRAIN]\".format(lr.score(X_train, y_train)))\n",
    "print(\"Logistic regression accuracy: {:2.2f} [TEST]\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â­âââââââââââââââââââââââââââââââ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> âââââââââââââââââââââââââââââââââ®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>df_info_test = df_infos2.iloc[n//<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>:].copy()                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>2 y_pred = lr.predict(X_test)                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>df_info_test[<span style=\"color: #808000; text-decoration-color: #808000\">'inner_truth'</span>] = y_pred                                                         <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>df_info_test                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â°âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'lr'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ­â\u001b[0m\u001b[31mââââââââââââââââââââââââââââââ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâââââââââââââââââââââââââââââââ\u001b[0m\u001b[31mââ®\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m1 \u001b[0mdf_info_test = df_infos2.iloc[n//\u001b[94m2\u001b[0m:].copy()                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[31mâ± \u001b[0m2 y_pred = lr.predict(X_test)                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m3 \u001b[0mdf_info_test[\u001b[33m'\u001b[0m\u001b[33minner_truth\u001b[0m\u001b[33m'\u001b[0m] = y_pred                                                         \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m4 \u001b[0mdf_info_test                                                                                 \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m5 \u001b[0m                                                                                             \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ°âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'lr'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_info_test = df_infos2.iloc[n//2:].copy()\n",
    "y_pred = lr.predict(X_test)\n",
    "df_info_test['inner_truth'] = y_pred\n",
    "df_info_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlk2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
