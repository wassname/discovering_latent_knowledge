{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload import your package\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /home/ubuntu/mambaforge/envs/dlk3/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/ubuntu/mambaforge/envs/dlk3/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    }
   ],
   "source": [
    "# from elk.extraction.prompt_loading import load_prompts\n",
    "from elk.extraction.extraction import Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prompts.prompt_loading import load_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 13 variants of each prompt\n"
     ]
    }
   ],
   "source": [
    "# %%prun\n",
    "cfg = Extract(\"HuggingFaceH4/starchat-beta\", datasets=[\"imdb\"], num_shots=1, binarize=True)\n",
    "cfg\n",
    "\n",
    "# loop through all prompts in this dataset\n",
    "split_type = \"train\"\n",
    "rank = 0\n",
    "ds_names = cfg.datasets\n",
    "world_size=1\n",
    "prompt_ds = load_prompts(\n",
    "    ds_names[0],\n",
    "    binarize=cfg.binarize,\n",
    "    num_shots=cfg.num_shots,\n",
    "    split_type=split_type,\n",
    "    template_path=cfg.template_path,\n",
    "    rank=rank,\n",
    "    world_size=world_size,\n",
    "    seed=cfg.seed,\n",
    ")\n",
    "g =iter(prompt_ds)\n",
    "b = next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%prun\n",
    "# b = next(g)\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7258e7f338f44046ad7b9552d1243da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 2\u001b[0m [a \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39;49m(tqdm(prompt_ds))]\n",
      "File \u001b[0;32m~/mambaforge/envs/dlk3/lib/python3.11/site-packages/tqdm/notebook.py:249\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    250\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    251\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    252\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/dlk3/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/mjc/elk/discovering_latent_knowledge/src/prompts/prompt_loading.py:132\u001b[0m, in \u001b[0;36mload_prompts\u001b[0;34m(ds_string, sys_instructions, binarize, num_shots, seed, split_type, template_path, rank, world_size, prompt_format)\u001b[0m\n\u001b[1;32m    129\u001b[0m     ds \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mto_iterable_dataset()\n\u001b[1;32m    131\u001b[0m \u001b[39mfor\u001b[39;00m example \u001b[39min\u001b[39;00m ds:\n\u001b[0;32m--> 132\u001b[0m     \u001b[39myield\u001b[39;00m _convert_to_prompts(\n\u001b[1;32m    133\u001b[0m         example,\n\u001b[1;32m    134\u001b[0m         binarize\u001b[39m=\u001b[39;49mbinarize,\n\u001b[1;32m    135\u001b[0m         label_column\u001b[39m=\u001b[39;49mlabel_column,\n\u001b[1;32m    136\u001b[0m         label_choices\u001b[39m=\u001b[39;49mlabel_choices,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    137\u001b[0m         prompter\u001b[39m=\u001b[39;49mprompter,\n\u001b[1;32m    138\u001b[0m         rng\u001b[39m=\u001b[39;49mrng,\n\u001b[1;32m    139\u001b[0m         sys_instructions\u001b[39m=\u001b[39;49msys_instructions,\n\u001b[1;32m    140\u001b[0m         fewshot_iter\u001b[39m=\u001b[39;49mfewshot_iter,\n\u001b[1;32m    141\u001b[0m         prompt_format\u001b[39m=\u001b[39;49mprompt_format,\n\u001b[1;32m    142\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/mjc/elk/discovering_latent_knowledge/src/prompts/prompt_loading.py:192\u001b[0m, in \u001b[0;36m_convert_to_prompts\u001b[0;34m(example, prompter, binarize, label_column, label_choices, rng, sys_instructions, fewshot_iter, prompt_format)\u001b[0m\n\u001b[1;32m    190\u001b[0m     fewshot_examples \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(fewshot_iter)\n\u001b[1;32m    191\u001b[0m     \u001b[39mif\u001b[39;00m lie: fewshot_examples \u001b[39m=\u001b[39m [{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39me, \u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m~\u001b[39me[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]} \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m fewshot_examples]\n\u001b[0;32m--> 192\u001b[0m     fewshot_texts \u001b[39m=\u001b[39m [\n\u001b[1;32m    193\u001b[0m         \u001b[39mdict\u001b[39;49m(user\u001b[39m=\u001b[39;49mq, response\u001b[39m=\u001b[39;49ma) \u001b[39mfor\u001b[39;49;00m q, a \u001b[39min\u001b[39;49;00m \u001b[39mmap\u001b[39;49m(template\u001b[39m.\u001b[39;49mapply, fewshot_examples)\n\u001b[1;32m    194\u001b[0m     ]\n\u001b[1;32m    195\u001b[0m     prompt_parts \u001b[39m=\u001b[39m fewshot_texts \u001b[39m+\u001b[39m prompt_parts\n\u001b[1;32m    197\u001b[0m prompt_parts[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m sys_instr\n",
      "File \u001b[0;32m~/Documents/mjc/elk/discovering_latent_knowledge/src/prompts/prompt_loading.py:192\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    190\u001b[0m     fewshot_examples \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(fewshot_iter)\n\u001b[1;32m    191\u001b[0m     \u001b[39mif\u001b[39;00m lie: fewshot_examples \u001b[39m=\u001b[39m [{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39me, \u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m~\u001b[39me[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]} \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m fewshot_examples]\n\u001b[0;32m--> 192\u001b[0m     fewshot_texts \u001b[39m=\u001b[39m [\n\u001b[1;32m    193\u001b[0m         \u001b[39mdict\u001b[39m(user\u001b[39m=\u001b[39mq, response\u001b[39m=\u001b[39ma) \u001b[39mfor\u001b[39;00m q, a \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(template\u001b[39m.\u001b[39mapply, fewshot_examples)\n\u001b[1;32m    194\u001b[0m     ]\n\u001b[1;32m    195\u001b[0m     prompt_parts \u001b[39m=\u001b[39m fewshot_texts \u001b[39m+\u001b[39m prompt_parts\n\u001b[1;32m    197\u001b[0m prompt_parts[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m sys_instr\n",
      "File \u001b[0;32m~/mambaforge/envs/dlk3/lib/python3.11/site-packages/elk/promptsource/templates.py:165\u001b[0m, in \u001b[0;36mTemplate.apply\u001b[0;34m(self, example, truncate, highlight_variables)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39manswer_choices\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m protected_example:\n\u001b[1;32m    163\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExample contains the restricted key \u001b[39m\u001b[39m'\u001b[39m\u001b[39manswer_choices\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m protected_example[\u001b[39m\"\u001b[39m\u001b[39manswer_choices\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_answer_choices_list(example)\n\u001b[1;32m    167\u001b[0m \u001b[39m# Renders the Jinja template\u001b[39;00m\n\u001b[1;32m    168\u001b[0m rendered_example \u001b[39m=\u001b[39m rtemplate\u001b[39m.\u001b[39mrender(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprotected_example)\n",
      "File \u001b[0;32m~/mambaforge/envs/dlk3/lib/python3.11/site-packages/elk/promptsource/templates.py:109\u001b[0m, in \u001b[0;36mTemplate.get_answer_choices_list\u001b[0;34m(self, example)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mif\u001b[39;00m jinja \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m rtemplate \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mfrom_string(jinja)\n\u001b[1;32m    110\u001b[0m protected_example \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_escape_pipe(example)\n\u001b[1;32m    111\u001b[0m rendered_choices \u001b[39m=\u001b[39m rtemplate\u001b[39m.\u001b[39mrender(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprotected_example)\n",
      "File \u001b[0;32m~/mambaforge/envs/dlk3/lib/python3.11/site-packages/jinja2/environment.py:1105\u001b[0m, in \u001b[0;36mEnvironment.from_string\u001b[0;34m(self, source, globals, template_class)\u001b[0m\n\u001b[1;32m   1103\u001b[0m gs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_globals(\u001b[39mglobals\u001b[39m)\n\u001b[1;32m   1104\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m template_class \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemplate_class\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_code(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile(source), gs, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/dlk3/lib/python3.11/site-packages/jinja2/environment.py:760\u001b[0m, in \u001b[0;36mEnvironment.compile\u001b[0;34m(self, source, name, filename, raw, defer_init)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(source, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    759\u001b[0m     source_hint \u001b[39m=\u001b[39m source\n\u001b[0;32m--> 760\u001b[0m     source \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse(source, name, filename)\n\u001b[1;32m    761\u001b[0m source \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(source, name, filename, defer_init\u001b[39m=\u001b[39mdefer_init)\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m raw:\n",
      "File \u001b[0;32m~/mambaforge/envs/dlk3/lib/python3.11/site-packages/jinja2/environment.py:617\u001b[0m, in \u001b[0;36mEnvironment._parse\u001b[0;34m(self, source, name, filename)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_parse\u001b[39m(\n\u001b[1;32m    614\u001b[0m     \u001b[39mself\u001b[39m, source: \u001b[39mstr\u001b[39m, name: t\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m], filename: t\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m]\n\u001b[1;32m    615\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m nodes\u001b[39m.\u001b[39mTemplate:\n\u001b[1;32m    616\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Internal parsing function used by `parse` and `compile`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 617\u001b[0m     \u001b[39mreturn\u001b[39;00m Parser(\u001b[39mself\u001b[39;49m, source, name, filename)\u001b[39m.\u001b[39mparse()\n",
      "File \u001b[0;32m~/mambaforge/envs/dlk3/lib/python3.11/site-packages/jinja2/parser.py:60\u001b[0m, in \u001b[0;36mParser.__init__\u001b[0;34m(self, environment, source, name, filename, state)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     52\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     53\u001b[0m     environment: \u001b[39m\"\u001b[39m\u001b[39mEnvironment\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     state: t\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     58\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menvironment \u001b[39m=\u001b[39m environment\n\u001b[0;32m---> 60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m environment\u001b[39m.\u001b[39;49m_tokenize(source, name, filename, state)\n\u001b[1;32m     61\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m name\n\u001b[1;32m     62\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39m=\u001b[39m filename\n",
      "File \u001b[0;32m~/mambaforge/envs/dlk3/lib/python3.11/site-packages/jinja2/environment.py:669\u001b[0m, in \u001b[0;36mEnvironment._tokenize\u001b[0;34m(self, source, name, filename, state)\u001b[0m\n\u001b[1;32m    666\u001b[0m source \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(source, name, filename)\n\u001b[1;32m    667\u001b[0m stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlexer\u001b[39m.\u001b[39mtokenize(source, name, filename, state)\n\u001b[0;32m--> 669\u001b[0m \u001b[39mfor\u001b[39;00m ext \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_extensions():\n\u001b[1;32m    670\u001b[0m     stream \u001b[39m=\u001b[39m ext\u001b[39m.\u001b[39mfilter_stream(stream)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(stream, TokenStream):\n",
      "File \u001b[0;32m~/mambaforge/envs/dlk3/lib/python3.11/site-packages/jinja2/environment.py:459\u001b[0m, in \u001b[0;36mEnvironment.iter_extensions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39miter_extensions\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mIterator[\u001b[39m\"\u001b[39m\u001b[39mExtension\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    458\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Iterates over the extensions by priority.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39msorted\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextensions\u001b[39m.\u001b[39mvalues(), key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mpriority))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "# [a for a in list(tqdm(prompt_ds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b['prompts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "<end>\n",
      "<|user|>if you like gangster type of movies, then this is the first one you should buy or at least rent, Al Pacino his performance is top notch. and the story is classic!! 10 / 10 !!!! Why isn't this movie in the TOP 250 list??\n",
      "Did the reviewer enjoy the movie?\n",
      "<|end|>\n",
      "<|response|>Yes\n",
      "<|end|>\n",
      "<|user|>George P. Cosmatos' \"Rambo: First Blood Part II\" is pure wish-fulfillment. The United States clearly didn't win the war in Vietnam. They caused damage to this country beyond the imaginable and this movie continues the fairy story of the oh-so innocent soldiers. The only bad guys were the leaders of the nation, who made this war happen. The character of Rambo is perfect to notice this. He is extremely patriotic, bemoans that US-Americans didn't appreciate and celebrate the achievements of the single soldier, but has nothing but distrust for leading officers and politicians. Like every film that defends the war (e.g. \"We Were Soldiers\") also this one avoids the need to give a comprehensible reason for the engagement in South Asia. And for that matter also the reason for every single US-American soldier that was there. Instead, Rambo gets to take revenge for the wounds of a whole nation. It would have been better to work on how to deal with the memories, rather than suppressing them. \"Do we get to win this time?\" Yes, you do.\n",
      "Did the reviewer enjoy the movie?\n",
      "<|end|>\n",
      "<|response|>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'No',\n",
       " 'question': '<|system|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n<end>\\n<|user|>if you like gangster type of movies, then this is the first one you should buy or at least rent, Al Pacino his performance is top notch. and the story is classic!! 10 / 10 !!!! Why isn\\'t this movie in the TOP 250 list??\\nDid the reviewer enjoy the movie?\\n<|end|>\\n<|response|>Yes\\n<|end|>\\n<|user|>George P. Cosmatos\\' \"Rambo: First Blood Part II\" is pure wish-fulfillment. The United States clearly didn\\'t win the war in Vietnam. They caused damage to this country beyond the imaginable and this movie continues the fairy story of the oh-so innocent soldiers. The only bad guys were the leaders of the nation, who made this war happen. The character of Rambo is perfect to notice this. He is extremely patriotic, bemoans that US-Americans didn\\'t appreciate and celebrate the achievements of the single soldier, but has nothing but distrust for leading officers and politicians. Like every film that defends the war (e.g. \"We Were Soldiers\") also this one avoids the need to give a comprehensible reason for the engagement in South Asia. And for that matter also the reason for every single US-American soldier that was there. Instead, Rambo gets to take revenge for the wounds of a whole nation. It would have been better to work on how to deal with the memories, rather than suppressing them. \"Do we get to win this time?\" Yes, you do.\\nDid the reviewer enjoy the movie?\\n<|end|>\\n<|response|>',\n",
       " 'answer_choices': ['No', 'Yes'],\n",
       " 'template_name': 'Reviewer Enjoyment Yes No',\n",
       " 'label_true': 0,\n",
       " 'label_instructed': 0,\n",
       " 'instructed_to_lie': False,\n",
       " 'sys_instr_name': 'truth'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "ps = b['prompts']\n",
    "c = random.choice(ps)\n",
    "print(c['question'])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ps[0]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['prompts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['template_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scratch prompt structure\n",
    "\n",
    "see https://github.com/EleutherAI/elk/blob/1b60b3bff348b00356cd15b5eb017f9c9bfdbae1/elk/promptsource/templates.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from elk.promptsource.templates import env\n",
    "\n",
    "f = '../src/prompts/templates/system.yaml'\n",
    "yaml_dict = yaml.load(open(f, 'r'), Loader=yaml.FullLoader)\n",
    "templates = yaml_dict[\"templates\"]\n",
    "jinja = templates['chatml']\n",
    "rtemplate = env.from_string(jinja)\n",
    "rtemplate.render(system=\"system2\", user=\"user2\", response=\"response2\")\n",
    "# rtemplate.render(system=\"\", user=\"user2\", response=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtemplate.apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlk2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
