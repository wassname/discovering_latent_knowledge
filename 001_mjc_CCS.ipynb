{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's implement CCS from scratch.\n",
    "This will deliberately be a simple (but less efficient) implementation to make everything as clear as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:54:44.191549Z",
     "start_time": "2023-05-20T01:54:41.824251Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wassname/miniforge3/envs/dlk2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM, AutoModelForCausalLM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "from transformers.models.auto.modeling_auto import AutoModel\n",
    "# from scipy.stats import zscore\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import gc\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:54:44.196607Z",
     "start_time": "2023-05-20T01:54:44.193276Z"
    }
   },
   "outputs": [],
   "source": [
    "# from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:54:27.257168Z",
     "start_time": "2023-05-20T01:54:27.254862Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:56:26.440636Z",
     "start_time": "2023-05-20T01:54:44.197666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/wassname/miniforge3/envs/dlk2/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/wassname/miniforge3/envs/dlk2/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wassname/miniforge3/envs/dlk2/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: /home/wassname/miniforge3/envs/jupyter2 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/wassname/miniforge3/envs/dlk2/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/share/gconf/cinnamon.mandatory.path')}\n",
      "  warn(msg)\n",
      "/home/wassname/miniforge3/envs/dlk2/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/share/gconf/cinnamon.default.path')}\n",
      "  warn(msg)\n",
      "/home/wassname/miniforge3/envs/dlk2/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('local/wassname-fractal-desktop'), PosixPath('@/tmp/.ICE-unix/5335,unix/wassname-fractal-desktop')}\n",
      "  warn(msg)\n",
      "/home/wassname/miniforge3/envs/dlk2/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('0'), PosixPath('1')}\n",
      "  warn(msg)\n",
      "/home/wassname/miniforge3/envs/dlk2/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/etc/xdg/xdg-cinnamon')}\n",
      "  warn(msg)\n",
      "/home/wassname/miniforge3/envs/dlk2/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/home/wassname/miniforge3/envs/dlk2/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "Loading checkpoint shards: 100%|██████████████| 2/2 [00:07<00:00,  3.78s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear8bitLt(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear8bitLt(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): Linear8bitLt(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear8bitLt(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "              (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "              (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here are a few different model options you can play around with:\n",
    "model_name = \"deberta\"\n",
    "model_name = \"gpt-j\"\n",
    "# model_name = \"t5\"\n",
    "model_name = \"llama\"\n",
    "model_name = \"alpaca\"\n",
    "finetuned = None\n",
    "\n",
    "model_options = dict(\n",
    "    device_map=\"auto\", \n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "\n",
    "if model_name == \"deberta\":\n",
    "    model_type = \"encoder\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v2-xxlarge\")\n",
    "    model = AutoModelForMaskedLM.from_pretrained(\"microsoft/deberta-v2-xxlarge\", **model_options)\n",
    "elif model_name == \"gpt-j\":\n",
    "    model_type = \"decoder\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\", **model_options)\n",
    "elif model_name == \"t5\":\n",
    "    model_type = \"encoder_decoder\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"t5-11b\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-11b\", **model_options)\n",
    "    model.parallelize()  # T5 is big enough that we may need to run it on multiple GPUs\n",
    "elif (\"llama\" in model_name) or (\"alpaca\" in model_name):\n",
    "    # https://github.com/deep-diver/LLM-As-Chatbot/blob/216abb559d00a0555f41a1426ac9db6c1abc24f3/models/alpaca.py\n",
    "    model_repo = \"Neko-Institute-of-Science/LLaMA-7B-HF\"\n",
    "    lora_repo = \"tloen/alpaca-lora-7b\"\n",
    "    model_type = \"decoder\"\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(model_repo)\n",
    "    model = LlamaForCausalLM.from_pretrained(model_repo, **model_options)\n",
    "    \n",
    "    if \"alpaca\" in model_name:\n",
    "        from peft import PeftModel\n",
    "        model = PeftModel.from_pretrained(\n",
    "            model, \n",
    "            lora_repo, \n",
    "            device_map='auto'#{'': 0}\n",
    "        )\n",
    "        \n",
    "    tokenizer.pad_token = 0\n",
    "    tokenizer.padding_side = \"left\"\n",
    "else:\n",
    "    raise NotADirectoryError(model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:56:26.444015Z",
     "start_time": "2023-05-20T01:56:26.442164Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "# tokenizer.truncation_side='Left'\n",
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:56:26.469934Z",
     "start_time": "2023-05-20T01:56:26.444768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29900, 29896)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the tokens for 0 and 1, we will use these later...\n",
    "id_0, id_1 = tokenizer('0')['input_ids'][-1], tokenizer('1')['input_ids'][-1]\n",
    "id_0, id_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-07T01:08:20.635Z"
    }
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T04:02:13.892383Z",
     "start_time": "2023-05-19T04:02:13.873377Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:56:27.020627Z",
     "start_time": "2023-05-20T01:56:26.470949Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/wassname/.cache/huggingface/modules/datasets_modules/datasets/amazon_polarity/a27b32b7e7b88eb274a8fa8ba0f654f1fe998a87c22547557317793b5d2772dc (last modified on Sat May  6 07:52:43 2023) since it couldn't be found locally at amazon_polarity.\n",
      "Found cached dataset amazon_polarity (/home/wassname/.cache/huggingface/datasets/amazon_polarity/amazon_polarity/3.0.0/a27b32b7e7b88eb274a8fa8ba0f654f1fe998a87c22547557317793b5d2772dc)\n",
      "100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  3.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'title', 'content'],\n",
       "        num_rows: 3600000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'title', 'content'],\n",
       "        num_rows: 400000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug\n",
    "datasets.logging.set_verbosity_info()\n",
    "\n",
    "\n",
    "# Let's just try IMDB for simplicity\n",
    "data = load_dataset(\"amazon_polarity\")\n",
    "# data = load_dataset(\"/home/wassname/.cache/huggingface/datasets/amazon_polarity/amazon_polarity/3.0.0/a27b32b7e7b88eb274a8fa8ba0f654f1fe998a87c22547557317793b5d2772dc/amazon_polarity-train-00003-of-00004.arrow\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T02:25:05.461369Z",
     "start_time": "2023-05-20T02:25:05.458241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \"I think this is a lovely family movie. There are plenty of hilarious scenes and heart-warming moments to be had throughout the movie. The actors are great and the effects well executed throughout. Danny Glover plays George Knox who manages the terrible baseball team 'The Angels' and is great throughout the film. Also fantastic are the young actors Joseph Gordon-Levitt and Milton Davis Jr. Christopher Lloyd is good as Al 'The Angel' and the effects are great in this top notch Disney movie. A touching and heart-warming movie which everyone should enjoy.\"\n",
      "Question: Is this review positive? \n",
      "Answer: 1\n",
      "---\n",
      "Review: \"The movie was the worst.... not!\"\n",
      "Question: Is this review negative?\n",
      "Answer: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def format_imdb(text, label):\n",
    "    return f\"\"\"Review: \"I think this is a lovely family movie. There are plenty of hilarious scenes and heart-warming moments to be had throughout the movie. The actors are great and the effects well executed throughout. Danny Glover plays George Knox who manages the terrible baseball team 'The Angels' and is great throughout the film. Also fantastic are the young actors Joseph Gordon-Levitt and Milton Davis Jr. Christopher Lloyd is good as Al 'The Angel' and the effects are great in this top notch Disney movie. A touching and heart-warming movie which everyone should enjoy.\"\n",
    "Question: Is this review positive? \n",
    "Answer: 1\n",
    "---\n",
    "Review: \"{text}\"\n",
    "Question: Is this review {'positive' if label else 'negative'}?\n",
    "Answer: \n",
    "\"\"\"\n",
    "\n",
    "def format_imdbs(texts, labels):\n",
    "    return [format_imdb(t, labels) for t in texts]\n",
    "\n",
    "print(format_imdb(\"The movie was the worst.... not!\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T02:25:05.902898Z",
     "start_time": "2023-05-20T02:25:05.898745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens\n",
    "len(tokenizer(format_imdb(\"The movie was the worst.... not!\", 0))['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First check models text output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T02:25:45.805378Z",
     "start_time": "2023-05-20T02:25:45.800064Z"
    }
   },
   "outputs": [],
   "source": [
    "# gen_config_raw = {\n",
    "#     \"temperature\": temperature,\n",
    "#     \"top_p\": top_p,\n",
    "#     \"top_k\": top_k,\n",
    "#     \"repetition_penalty\": repetition_penalty,\n",
    "#     \"max_new_tokens\": max_new_tokens,\n",
    "#     \"num_beams\": num_beams,\n",
    "#     \"use_cache\": use_cache,\n",
    "#     \"do_sample\": do_sample,\n",
    "#     \"eos_token_id\": eos_token_id, \n",
    "#     \"pad_token_id\": pad_token_id\n",
    "# }\n",
    "\n",
    "def get_output(model, tokenizer, input_text, add_bos_token=False, truncation_length=400):\n",
    "    \"\"\"\n",
    "    Given a decoder model and some text, gets the hidden states (in a given layer, by default the last) on that input text\n",
    "\n",
    "    Returns a numpy array of shape (hidden_dim,)\n",
    "    \"\"\"\n",
    "    if not isinstance(input_text, list):\n",
    "        input_text = [input_text]\n",
    "    # tokenize (adding the EOS token this time)\n",
    "#     input_text = [i + tokenizer.eos_token for i in input_text]\n",
    "#     input_text = [i[-1000:] for i in input_text]\n",
    "    input_ids = tokenizer(input_text, \n",
    "                          return_tensors=\"pt\",\n",
    "#                           truncation=True, \n",
    "#                           padding=True,\n",
    "#                           max_length=600,\n",
    "#                           add_special_tokens=False,\n",
    "                         ).input_ids.to(model.device)\n",
    "#     print('input_ids', input_ids.shape)\n",
    "\n",
    "    # remove bos token? https://github.com/oobabooga/text-generation-webui/blob/1b52bddfcc70d2db88257d36f1c6d182573588c4/modules/text_generation.py#L36\n",
    "    if not add_bos_token and input_ids[0][0] == tokenizer.bos_token_id:\n",
    "        input_ids = input_ids[:, 1:]\n",
    "\n",
    "\n",
    "    # Llama adds this extra token when the first character is '\\n', and this\n",
    "    # compromises the stopping criteria, so we just remove it\n",
    "    if type(tokenizer) is LlamaTokenizer and input_ids[0][0] == 29871:\n",
    "        print('removed extra \\n token')\n",
    "        input_ids = input_ids[:, 1:]\n",
    "        \n",
    "    # Handling truncation\n",
    "    if truncation_length is not None:\n",
    "        input_ids = input_ids[:, -truncation_length:]\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids=input_ids, max_length=400)\n",
    "#     print(output)\n",
    "    \n",
    "    text_q = tokenizer.batch_decode(input_ids, skip_special_tokens=False)\n",
    "    text_ans = tokenizer.batch_decode(output, skip_special_tokens=False)#, skip_prompt=True, skip_special_tokens=True)\n",
    "    print(text_q[0])\n",
    "    print('-'*40+'answ'+'-'*40)\n",
    "    print(text_ans[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:54:09.323908Z",
     "start_time": "2023-05-20T01:54:09.321888Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T02:25:46.260946Z",
     "start_time": "2023-05-20T02:25:46.258734Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id=0\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T02:25:46.401304Z",
     "start_time": "2023-05-20T02:25:46.398898Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "text, true_label = data['test'][idx][\"content\"], data['test'][idx][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T02:25:53.587709Z",
     "start_time": "2023-05-20T02:25:46.528753Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \"I think this is a lovely family movie. There are plenty of hilarious scenes and heart-warming moments to be had throughout the movie. The actors are great and the effects well executed throughout. Danny Glover plays George Knox who manages the terrible baseball team 'The Angels' and is great throughout the film. Also fantastic are the young actors Joseph Gordon-Levitt and Milton Davis Jr. Christopher Lloyd is good as Al 'The Angel' and the effects are great in this top notch Disney movie. A touching and heart-warming movie which everyone should enjoy.\"\n",
      "Question: Is this review positive? \n",
      "Answer: 1\n",
      "---\n",
      "Review: \"Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren't included I would still consider the collection worth it.\"\n",
      "Question: Is this review positive?\n",
      "Answer: \n",
      "\n",
      "----------------------------------------answ----------------------------------------\n",
      "Review: \"I think this is a lovely family movie. There are plenty of hilarious scenes and heart-warming moments to be had throughout the movie. The actors are great and the effects well executed throughout. Danny Glover plays George Knox who manages the terrible baseball team 'The Angels' and is great throughout the film. Also fantastic are the young actors Joseph Gordon-Levitt and Milton Davis Jr. Christopher Lloyd is good as Al 'The Angel' and the effects are great in this top notch Disney movie. A touching and heart-warming movie which everyone should enjoy.\"\n",
      "Question: Is this review positive? \n",
      "Answer: 1\n",
      "---\n",
      "Review: \"Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren't included I would still consider the collection worth it.\"\n",
      "Question: Is this review positive?\n",
      "Answer: \n",
      "---\n",
      "Review: \"This is a great movie. It has a great storyline and the acting is superb. The characters are well developed and the plot is interesting. The special effects are great and the cinematography is beautiful. The music is also very good and fits the mood of the\n"
     ]
    }
   ],
   "source": [
    "input_text = [format_imdb(text, 1)]\n",
    "# input_text = [i + tokenizer.eos_token for i in input_text]\n",
    "get_output(model, tokenizer, input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write code for extracting hidden states given a model and text. \n",
    "How we do this exactly will depend on the type of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T02:27:33.628985Z",
     "start_time": "2023-05-20T02:27:33.623501Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_decoder_hidden_states(model, tokenizer, input_text, layers=[2, -2], add_bos_token=False, truncation_length=400):\n",
    "    \"\"\"\n",
    "    Given a decoder model and some text, gets the hidden states (in a given layer, by default the last) on that input text\n",
    "\n",
    "    Returns a numpy array of shape (hidden_dim,)\n",
    "    \"\"\"\n",
    "    if not isinstance(input_text, list):\n",
    "        input_text = [input_text]\n",
    "    # tokenize (adding the EOS token this time)\n",
    "    input_text = [i + tokenizer.eos_token for i in input_text]\n",
    "    input_text = [i[-1000:] for i in input_text]\n",
    "    input_ids = tokenizer(input_text, \n",
    "                          return_tensors=\"pt\",\n",
    "#                           truncation=True, \n",
    "                          padding=True,\n",
    "#                           max_length=600\n",
    "                         ).input_ids.to(model.device)\n",
    "#     print('input_ids', input_ids.shape)\n",
    "\n",
    "\n",
    "    # remove bos token? https://github.com/oobabooga/text-generation-webui/blob/1b52bddfcc70d2db88257d36f1c6d182573588c4/modules/text_generation.py#L36\n",
    "    if not add_bos_token and input_ids[0][0] == tokenizer.bos_token_id:\n",
    "        input_ids = input_ids[:, 1:]\n",
    "\n",
    "\n",
    "    # Llama adds this extra token when the first character is '\\n', and this\n",
    "    # compromises the stopping criteria, so we just remove it\n",
    "    if type(tokenizer) is LlamaTokenizer and input_ids[0][0] == 29871:\n",
    "        print('removed extra \\n token')\n",
    "        input_ids = input_ids[:, 1:]\n",
    "        \n",
    "    # Handling truncation\n",
    "    if truncation_length is not None:\n",
    "        input_ids = input_ids[:, -truncation_length:]\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, \n",
    "                       output_hidden_states=True,\n",
    "#                        , output_attentions=True\n",
    "                       use_cache=True,\n",
    "                       \n",
    "                      )\n",
    "    \n",
    "    # the output is large, so we will just select what we want 1) the first token with[:, 0]\n",
    "    # 2) selected layers with [layers]\n",
    "#     output['attentions'] = [output['attentions'][i] for i in layers]\n",
    "#     output['attentions'] = [v.detach().cpu()[:, -1] for v in output['attentions']]\n",
    "#     output['attentions'] = torch.concat(output['attentions'])\n",
    "    \n",
    "    \n",
    "    # dims [Batch, Token, Probs?]\n",
    "    output['hidden_states'] = torch.stack([output['hidden_states'][i] for i in layers], 1).detach().cpu()\n",
    "    # dims [Batch, Layers, Seq_Token, Probs?] e.g. torch.Size([3, 2, 284, 4096])\n",
    "    \n",
    "    # dims [Batch, ?, Output_Tokens] e.g. torch.Size([3, 284, 32000])\n",
    "    o = output['logits'].detach().cpu().float().softmax(-1)\n",
    "    \n",
    "    text_q = [tokenizer.decode(oo) for oo in input_ids]\n",
    "    text_ans = [tokenizer.decode(oo) for oo in o.argmax(-1)]\n",
    "\n",
    "    nth_place = 0\n",
    "    prob_0, prob1 = o[:, nth_place][:, [id_0, id_1]].T # get the prob of 0 vs 1 in nth place in answer\n",
    "    output['ans'] = (prob1/(prob_0+prob1))\n",
    "    # FIXME output batch\n",
    "    return dict(hidden_states=output['hidden_states'], ans=output['ans'], text_ans=text_ans, text_q=text_q\n",
    "#                 , attentions=output['attentions']\n",
    "               )\n",
    "\n",
    "def get_hidden_states(model, tokenizer, input_text, layers=[2, -2], model_type=\"encoder\"):\n",
    "    fn = {\n",
    "          \"decoder\": get_decoder_hidden_states}[model_type]\n",
    "\n",
    "    return fn(model, tokenizer, input_text, layers=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T02:27:33.946048Z",
     "start_time": "2023-05-20T02:27:33.944125Z"
    }
   },
   "outputs": [],
   "source": [
    "# input_text = [format_imdb(text, 0)]\n",
    "# input_text = [i + tokenizer.eos_token for i in input_text]\n",
    "# input_ids = tokenizer(input_text, \n",
    "#                       return_tensors=\"pt\",\n",
    "#                       truncation=True, \n",
    "#                       padding=True,\n",
    "#                       max_length=300).input_ids.to(model.device)\n",
    "# print(tokenizer.decode(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T02:27:34.584342Z",
     "start_time": "2023-05-20T02:27:34.092856Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unit test\n",
    "idx = 0\n",
    "text, true_label = data['test'][idx][\"content\"], data['test'][idx][\"label\"]\n",
    "neg_hs = get_hidden_states(model, tokenizer, format_imdb(text, 0), model_type=model_type)\n",
    "pos_hs = get_hidden_states(model, tokenizer, format_imdb(text, 1), model_type=model_type)\n",
    "# neg_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T02:27:34.588474Z",
     "start_time": "2023-05-20T02:27:34.585702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------input----------------------------------------\n",
      " hout. Danny Glover plays George Knox who manages the terrible baseball team 'The Angels' and is great throughout the film. Also fantastic are the young actors Joseph Gordon-Levitt and Milton Davis Jr. Christopher Lloyd is good as Al 'The Angel' and the effects are great in this top notch Disney movie. A touching and heart-warming movie which everyone should enjoy.\"\n",
      "Question: Is this review positive? \n",
      "Answer: 1\n",
      "---\n",
      "Review: \"My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I'm in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life's hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"\"\n",
      "Question: Is this review negative?\n",
      "Answer: \n",
      "</s>\n",
      "----------------------------------------answ----------------------------------------\n",
      " Belowen\n",
      "us hadver, a,x, isages a team situation team.The Brookels'. and is trying at. film.\n",
      " stastic is the supporting actors who Gordon-Levitt and Ches Williams who. who Lloyd plays also as thevinThe Bull' who the rest are great. the film notch family production.\n",
      " musting and funwwarming film that is should watch.\n",
      "\": What this movie based or\n",
      " AnswerAnswer: Yes\n",
      "0\n",
      "\n",
      "Questionview: \"This reviewely wiferic been of the mostREATEATE in all generation. She' been to her CD many monthsEARS and it still loveVE it! She I hearm feeling the bad mood,' me smile even, When must dayood and makesaporates. a in a rain. I is is makesozes classIFE and IERYally are superawss perfectUNFFNING. theics are make me I of the's great gems. Bu CD a must islandle CD for my collection. I isn isn made it big is beyond a me. Sheone I listen this CD I matter what or white or or or old, it or female,VERYONEDY lov the thing:W is that?\"?\"\n",
      "Question: Is this review positive?\n",
      "Answer: 0---<s>\n",
      "================================================================================\n",
      "----------------------------------------input----------------------------------------\n",
      " hout. Danny Glover plays George Knox who manages the terrible baseball team 'The Angels' and is great throughout the film. Also fantastic are the young actors Joseph Gordon-Levitt and Milton Davis Jr. Christopher Lloyd is good as Al 'The Angel' and the effects are great in this top notch Disney movie. A touching and heart-warming movie which everyone should enjoy.\"\n",
      "Question: Is this review positive? \n",
      "Answer: 1\n",
      "---\n",
      "Review: \"My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I'm in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life's hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"\"\n",
      "Question: Is this review positive?\n",
      "Answer: \n",
      "</s>\n",
      "----------------------------------------answ----------------------------------------\n",
      " Belowen\n",
      "us hadver, a,x, isages a team situation team.The Brookels'. and is trying at. film.\n",
      " stastic is the supporting actors who Gordon-Levitt and Ches Williams who. who Lloyd plays also as thevinThe Bull' who the rest are great. the film notch family production.\n",
      " musting and funwwarming film that is should watch.\n",
      "\": What this movie based or\n",
      " AnswerAnswer: Yes\n",
      "0\n",
      "\n",
      "Questionview: \"This reviewely wiferic been of the mostREATEATE in all generation. She' been to her CD many monthsEARS and it still loveVE it! She I hearm feeling the bad mood,' me feel even, When must mood and makesaporates. a in a rain. I is is makesozes classIFE and IERYally are superawss perfectUNPENING. theics are make me I of the's great gems. Bu CD a must islandle CD for my collection. I isn' made it big is beyond a me. She song I listen this CD I matter what or white or or or old, it or female,VERYONEDY lov the thing:W is that?\"?\"\n",
      "Question: Is this review positive?\n",
      "Answer: 1---<s>\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*40+'input'+'-'*40)\n",
    "print(neg_hs['text_q'][0])\n",
    "print('-'*40+'answ'+'-'*40)\n",
    "print(neg_hs['text_ans'][0])\n",
    "print('='*80)\n",
    "print('-'*40+'input'+'-'*40)\n",
    "print(pos_hs['text_q'][0])\n",
    "print('-'*40+'answ'+'-'*40)\n",
    "print(pos_hs['text_ans'][0])\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T02:27:34.617886Z",
     "start_time": "2023-05-20T02:27:34.589316Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # unit tests\n",
    "# idx = 0\n",
    "# n=10\n",
    "# batch_size=3\n",
    "# ds_subset = data['test'].shuffle(42).select(range(n))\n",
    "# dl = DataLoader(ds_subset, batch_size=batch_size, shuffle=True)\n",
    "# batch = next(iter(dl))\n",
    "\n",
    "# texts, true_labels = batch[\"content\"], batch[\"label\"]\n",
    "# neg_hs = get_hidden_states(model, tokenizer, format_imdbs(texts, 0), model_type=model_type)\n",
    "# neg_hs\n",
    "# for k,v in neg_hs.items():\n",
    "#     print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's write code for formatting data and for getting all the hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:56:35.161371Z",
     "start_time": "2023-05-20T01:56:35.145412Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_hidden_states_many_examples(model, tokenizer, data, model_type, n=100, layers=[2, -2], batch_size=3):\n",
    "    \"\"\"\n",
    "    Given an encoder-decoder model, a list of data, computes the contrast hidden states on n random examples.\n",
    "    Returns numpy arrays of shape (n, hidden_dim) for each candidate label, along with a boolean numpy array of shape (n,)\n",
    "    with the ground truth labels\n",
    "    \n",
    "    This is deliberately simple so that it's easy to understand, rather than being optimized for efficiency\n",
    "    \"\"\"\n",
    "    # setup\n",
    "    model.eval()\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    ds_subset = data['test'].shuffle(42).select(range(n))\n",
    "    dl = DataLoader(ds_subset, batch_size=batch_size, shuffle=True)\n",
    "    for batch in tqdm(dl):\n",
    "        text, true_label = batch[\"content\"], batch[\"label\"]\n",
    "        neg = get_hidden_states(model, tokenizer, format_imdbs(text, 0), model_type=model_type, layers=layers)\n",
    "        pos = get_hidden_states(model, tokenizer, format_imdbs(text, 1), model_type=model_type, layers=layers)\n",
    "\n",
    "        # collect\n",
    "        b = len(text)\n",
    "#         print(neg['hidden_states'].shape)\n",
    "        res.append([\n",
    "            neg['hidden_states'].reshape((b,-1)),\n",
    "            pos['hidden_states'].reshape((b,-1)),\n",
    "            true_label,\n",
    "            neg['ans'],  \n",
    "            pos['ans'],            \n",
    "        ])\n",
    "    \n",
    "    # FIXME not all the hidden state are the same size, wat\n",
    "    res = [np.concatenate(r) for r in zip(*res)]\n",
    "    return res\n",
    "    all_neg_hs, all_pos_hs, all_gt_labels, all_neg_ans, all_pos_ans = res\n",
    "    return all_neg_hs, all_pos_hs, all_gt_labels, all_neg_ans, all_pos_ans\n",
    "#     return all_neg_hs, all_pos_hs, all_gt_labels, np.array(all_neg_ans), np.array(all_pos_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T03:15:48.077547Z",
     "start_time": "2023-05-07T03:15:48.074666Z"
    }
   },
   "source": [
    "# Lets verify that the models answers are good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:56:35.183039Z",
     "start_time": "2023-05-20T01:56:35.162312Z"
    }
   },
   "outputs": [],
   "source": [
    "# neg_hs, pos_hs, y, all_neg_ans, all_pos_ans = get_hidden_states_many_examples(model, tokenizer, data, model_type, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speed\n",
    "\n",
    "- 60second for 100 no batching. 1.7 ex/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:56:35.501003Z",
     "start_time": "2023-05-20T01:56:35.184047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.640525Z",
     "start_time": "2023-05-20T01:56:35.502054Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/wassname/.cache/huggingface/datasets/amazon_polarity/amazon_polarity/3.0.0/a27b32b7e7b88eb274a8fa8ba0f654f1fe998a87c22547557317793b5d2772dc/cache-0a5d0b47b5e8dfc6.arrow\n",
      "100%|███████████████████████████████████████| 34/34 [00:27<00:00,  1.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 neg_hs, pos_hs, y, all_neg_ans, all_pos_ans = get_hidden_states_many_examples(model, tok     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>gc.collect()                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_hidden_states_many_examples</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">33</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>])                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># FIXME not all the hidden state are the same size, wat</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>33 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>res = [np.concatenate(r) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> r <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">zip</span>(*res)]                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> res                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>all_neg_hs, all_pos_hs, all_gt_labels, all_neg_ans, all_pos_ans = res                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> all_neg_hs, all_pos_hs, all_gt_labels, all_neg_ans, all_pos_ans                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">33</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>])                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># FIXME not all the hidden state are the same size, wat</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>33 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>res = [np.concatenate(r) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> r <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">zip</span>(*res)]                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> res                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>all_neg_hs, all_pos_hs, all_gt_labels, all_neg_ans, all_pos_ans = res                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> all_neg_hs, all_pos_hs, all_gt_labels, all_neg_ans, all_pos_ans                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">concatenate</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>all the input array dimensions except for the concatenation axis must match exactly, but along \n",
       "dimension <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, the array at index <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> has size <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2285568</span> and the array at index <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> has size <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1908736</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 neg_hs, pos_hs, y, all_neg_ans, all_pos_ans = get_hidden_states_many_examples(model, tok     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0mgc.collect()                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mget_hidden_states_many_examples\u001b[0m:\u001b[94m33\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m30 \u001b[0m\u001b[2m│   │   \u001b[0m])                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m31 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m32 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# FIXME not all the hidden state are the same size, wat\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m33 \u001b[2m│   \u001b[0mres = [np.concatenate(r) \u001b[94mfor\u001b[0m r \u001b[95min\u001b[0m \u001b[96mzip\u001b[0m(*res)]                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m34 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m res                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m│   \u001b[0mall_neg_hs, all_pos_hs, all_gt_labels, all_neg_ans, all_pos_ans = res                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m all_neg_hs, all_pos_hs, all_gt_labels, all_neg_ans, all_pos_ans                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<listcomp>\u001b[0m:\u001b[94m33\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m30 \u001b[0m\u001b[2m│   │   \u001b[0m])                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m31 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m32 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# FIXME not all the hidden state are the same size, wat\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m33 \u001b[2m│   \u001b[0mres = [np.concatenate(r) \u001b[94mfor\u001b[0m r \u001b[95min\u001b[0m \u001b[96mzip\u001b[0m(*res)]                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m34 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m res                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m│   \u001b[0mall_neg_hs, all_pos_hs, all_gt_labels, all_neg_ans, all_pos_ans = res                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m all_neg_hs, all_pos_hs, all_gt_labels, all_neg_ans, all_pos_ans                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mconcatenate\u001b[0m:\u001b[94m200\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mall the input array dimensions except for the concatenation axis must match exactly, but along \n",
       "dimension \u001b[1;36m1\u001b[0m, the array at index \u001b[1;36m0\u001b[0m has size \u001b[1;36m2285568\u001b[0m and the array at index \u001b[1;36m1\u001b[0m has size \u001b[1;36m1908736\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neg_hs, pos_hs, y, all_neg_ans, all_pos_ans = get_hidden_states_many_examples(model, tokenizer, data, model_type)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.641742Z",
     "start_time": "2023-05-20T01:57:03.641735Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_pos_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.642523Z",
     "start_time": "2023-05-20T01:57:03.642517Z"
    }
   },
   "outputs": [],
   "source": [
    "# roc_auc_score\n",
    "pos_score = roc_auc_score(y, all_pos_ans)\n",
    "neg_score = roc_auc_score(y, all_neg_ans)\n",
    "pos_score, neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T11:32:21.359783Z",
     "start_time": "2023-05-14T11:32:20.787141Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.643517Z",
     "start_time": "2023-05-20T01:57:03.643507Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy_score\n",
    "pos_score = accuracy_score(y, (all_pos_ans>0.)*1.0)\n",
    "neg_score = accuracy_score(y, (all_neg_ans<0.5)*1.0)\n",
    "pos_score, neg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's verify that the model's representations are good\n",
    "\n",
    "Before trying CCS, let's make sure there exists a direction that classifies examples as true vs false with high accuracy; if supervised logistic regression accuracy is bad, there's no hope of unsupervised CCS doing well.\n",
    "\n",
    "Note that because logistic regression is supervised we expect it to do better but to have worse generalisation that equivilent unsupervised methods. However in this case CSS is using a deeper model so it is more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.644197Z",
     "start_time": "2023-05-20T01:57:03.644190Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's create a simple 50/50 train split (the data is already randomized)\n",
    "n = len(y)\n",
    "\n",
    "neg_hs2 = torch.from_numpy(np.stack([h.flatten() for h in neg_hs], 0))\n",
    "pos_hs2 = torch.from_numpy(np.stack([h.flatten() for h in pos_hs], 0))\n",
    "\n",
    "neg_hs_train, neg_hs_test = neg_hs2[:n//2], neg_hs2[n//2:]\n",
    "pos_hs_train, pos_hs_test = pos_hs2[:n//2], pos_hs2[n//2:]\n",
    "y_train, y_test = y[:n//2], y[n//2:]\n",
    "\n",
    "# for simplicity we can just take the difference between positive and negative hidden states\n",
    "# (concatenating also works fine)\n",
    "x_train = neg_hs_train - pos_hs_train\n",
    "x_test = neg_hs_test - pos_hs_test\n",
    "\n",
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "lr.fit(x_train, y_train)\n",
    "print(\"Logistic regression accuracy: {} [TRAIN]\".format(lr.score(x_train, y_train)))\n",
    "print(\"Logistic regression accuracy: {} [TEST]\".format(lr.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T00:05:52.801860Z",
     "start_time": "2023-05-14T00:05:52.784513Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try CCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.644851Z",
     "start_time": "2023-05-20T01:57:03.644841Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPProbe(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "#             nn.Linear(100, 100),\n",
    "#             nn.ReLU(),\n",
    "            nn.Linear(100, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T05:40:58.250804Z",
     "start_time": "2023-05-07T05:40:58.230537Z"
    }
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T11:16:41.661985Z",
     "start_time": "2023-05-07T11:16:41.650129Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.645452Z",
     "start_time": "2023-05-20T01:57:03.645446Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Train CCS without any labels\n",
    "# ccs = CCS(neg_hs_train, pos_hs_train, linear=False)\n",
    "# ccs.repeated_train()\n",
    "\n",
    "# # Evaluate\n",
    "# ccs_acc = ccs.get_acc(neg_hs_train, pos_hs_train, y_train)\n",
    "# print(\"CCS nonlinear train accuracy: {}\".format(ccs_acc))\n",
    "\n",
    "# ccs_acc = ccs.get_acc(neg_hs_test, pos_hs_test, y_test)\n",
    "# print(\"CCS nonlinear test accuracy: {}\".format(ccs_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.645991Z",
     "start_time": "2023-05-20T01:57:03.645985Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Train CCS without any labels\n",
    "# ccs = CCS(neg_hs_train, pos_hs_train, linear=True)\n",
    "# ccs.repeated_train()\n",
    "\n",
    "# # Evaluate\n",
    "# ccs_acc = ccs.get_acc(neg_hs_train, pos_hs_train, y_train)\n",
    "# print(\"CCS train accuracy: {}\".format(ccs_acc))\n",
    "\n",
    "# ccs_acc = ccs.get_acc(neg_hs_test, pos_hs_test, y_test)\n",
    "# print(\"CCS test accuracy: {}\".format(ccs_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T11:12:59.972960Z",
     "start_time": "2023-05-07T11:12:59.964090Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T04:12:55.004017Z",
     "start_time": "2023-05-19T04:12:55.004011Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T11:34:43.243172Z",
     "start_time": "2023-05-14T11:34:43.240582Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.646546Z",
     "start_time": "2023-05-20T01:57:03.646539Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# def normalize(x):\n",
    "#     \"\"\"\n",
    "#     Mean-normalizes the data x (of shape (n, d))\n",
    "#     If self.var_normalize, also divides by the standard deviation\n",
    "#     \"\"\"\n",
    "#     normalized_x = x - x.mean(axis=0, keepdims=True)\n",
    "#     if self.var_normalize:\n",
    "#         normalized_x /= normalized_x.std(axis=0, keepdims=True)\n",
    "\n",
    "#     return normalized_x\n",
    "\n",
    "\n",
    "class IMBDHSDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self,\n",
    "                 model: AutoModel,\n",
    "                 tokenizer: AutoTokenizer,\n",
    "                 model_type=\"decoder\",\n",
    "                 dataset_name=\"amazon_polarity\",\n",
    "                 batch_size=32,\n",
    "                 n=200,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.save_hyperparameters(ignore=[\"model\", \"tokenizer\"])\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "\n",
    "        self.dataset = load_dataset(self.hparams.dataset_name, split=\"test\")\n",
    "\n",
    "        neg_hs, pos_hs, y, all_neg_ans, all_pos_ans = get_hidden_states_many_examples(\n",
    "            self.model, self.tokenizer, self.dataset, self.hparams.model_type, n=self.hparams.n, layers=[2, -2])\n",
    "\n",
    "        # let's create a simple 50/50 train split (the data is already randomized)\n",
    "        n = len(y)\n",
    "        val_split = int(n * 0.5)\n",
    "        test_split = int(n * 0.75)\n",
    "        neg_hs_train, pos_hs_train, y_train = neg_hs[:\n",
    "                                                     val_split], pos_hs[:\n",
    "                                                                        val_split], y[:\n",
    "                                                                                      val_split]\n",
    "        neg_hs_val, pos_hs_val, y_val = neg_hs[val_split:test_split], pos_hs[\n",
    "            val_split:test_split], y[val_split:test_split]\n",
    "        neg_hs_test, pos_hs_test, y_test = neg_hs[test_split:], pos_hs[\n",
    "            test_split:], y[test_split:]\n",
    "\n",
    "        # for simplicity we can just take the difference between positive and negative hidden states\n",
    "        # (concatenating also works fine)\n",
    "        self.x_train = neg_hs_train - pos_hs_train\n",
    "        self.x_val = neg_hs_val - pos_hs_val\n",
    "        self.x_test = neg_hs_test - pos_hs_test\n",
    "\n",
    "        # normalize\n",
    "        self.scaler = RobustScaler()\n",
    "        self.scaler.fit(self.x_train)\n",
    "        self.x_train = self.scaler.transform(self.x_train)\n",
    "        self.x_val = self.scaler.transform(self.x_val)\n",
    "        self.x_test = self.scaler.transform(self.x_test)\n",
    "\n",
    "        self.ds_train = TensorDataset(torch.from_numpy(neg_hs_train).float(),\n",
    "                                      torch.from_numpy(pos_hs_train).float(),\n",
    "                                      torch.from_numpy(y_train).float())\n",
    "\n",
    "        self.ds_val = TensorDataset(torch.from_numpy(neg_hs_val).float(),\n",
    "                                    torch.from_numpy(pos_hs_val).float(),\n",
    "                                    torch.from_numpy(y_val).float())\n",
    "\n",
    "        self.ds_test = TensorDataset(torch.from_numpy(neg_hs_test).float(),\n",
    "                                     torch.from_numpy(pos_hs_test).float(),\n",
    "                                     torch.from_numpy(y_test).float())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds_train,\n",
    "                          batch_size=self.hparams.batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds_val, batch_size=self.hparams.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.ds_test, batch_size=self.hparams.batch_size)\n",
    "\n",
    "\n",
    "# test\n",
    "dm = IMBDHSDataModule(model, tokenizer)\n",
    "dm.setup('train')\n",
    "dl = dm.val_dataloader()\n",
    "b = next(iter(dl))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.647107Z",
     "start_time": "2023-05-20T01:57:03.647101Z"
    }
   },
   "outputs": [],
   "source": [
    "dm.x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightningModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.647739Z",
     "start_time": "2023-05-20T01:57:03.647733Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.648618Z",
     "start_time": "2023-05-20T01:57:03.648611Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_loss(p0, p1):\n",
    "    \"\"\"\n",
    "    Returns the CCS loss for two probabilities each of shape (n,1) or (n,)\n",
    "    \"\"\"\n",
    "    informative_loss = (torch.min(p0, p1)**2).mean(0)\n",
    "    consistent_loss = ((p0 - (1-p1))**2).mean(0)\n",
    "    return informative_loss + consistent_loss\n",
    "\n",
    "\n",
    "def get_acc(p0, p1, y):\n",
    "    avg_confidence = 0.5*(p0 + (1-p1))\n",
    "    predictions = (avg_confidence.detach().cpu().numpy() < 0.5).astype(int)[:, 0]\n",
    "    \n",
    "    # TODO f1\n",
    "    conf = (avg_confidence.detach().cpu().numpy() )[:, 0]\n",
    "    \n",
    "    acc = (predictions == y.cpu().numpy()).mean()\n",
    "    acc = max(acc, 1 - acc)\n",
    "    return predictions, acc\n",
    "\n",
    "def get_f1(p0, p1, y):\n",
    "    avg_confidence = 0.5*(p0 + (1-p1))\n",
    "    predictions = (avg_confidence.detach().cpu().numpy() < 0.5).astype(int)[:, 0]\n",
    "    \n",
    "    # TODO f1\n",
    "    conf = (avg_confidence.detach().cpu().numpy() )[:, 0]\n",
    "    auc = roc_auc_score(y.cpu().numpy(), predictions)\n",
    "    \n",
    "    auc = max(auc, 1 - auc)\n",
    "    return predictions, auc\n",
    "\n",
    "class CSS(pl.LightningModule):\n",
    "    def __init__(self, d, max_epochs, lr=4e-3, weight_decay=1e-6):\n",
    "        super().__init__()\n",
    "        self.probe = MLPProbe(d)\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.probe(x)\n",
    "        \n",
    "    def _step(self, batch, batch_idx, stage='train'):\n",
    "        x0, x1, y = batch\n",
    "        p0, p1 = self(x0), self(x1)\n",
    "        \n",
    "        loss = get_loss(p0, p1)\n",
    "        \n",
    "        self.log(f\"{stage}/loss\", loss)\n",
    "        \n",
    "        predictions, acc = get_acc(p0, p1, y)\n",
    "        self.log(f\"{stage}/acc\", acc)\n",
    "        predictions, f1 = get_f1(p0, p1, y)\n",
    "        self.log(f\"{stage}/f1\", f1)\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx=0):\n",
    "        return self._step(batch, batch_idx, stage='val')\n",
    "    \n",
    "    def prediction_step(self, batch, batch_idx):\n",
    "        x0, x1, y = batch\n",
    "        p0, p1 = self(x0), self(x1)\n",
    "        predictions, acc = get_acc(p0, p1, y)\n",
    "        return predictions \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=self.hparams.max_epochs, eta_min=self.hparams.lr / 50\n",
    "        )\n",
    "        return [optimizer], [lr_scheduler]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T10:58:56.488668Z",
     "start_time": "2023-05-07T10:58:56.488662Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T06:17:57.365689Z",
     "start_time": "2023-05-14T06:17:57.356995Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.649120Z",
     "start_time": "2023-05-20T01:57:03.649114Z"
    }
   },
   "outputs": [],
   "source": [
    "# init the autoencoder\n",
    "max_epochs = 1000\n",
    "d = b[0].shape[-1]\n",
    "net = CSS(d=d, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.649727Z",
     "start_time": "2023-05-20T01:57:03.649721Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_loader = utils.data.DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.650409Z",
     "start_time": "2023-05-20T01:57:03.650402Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
    "trainer = pl.Trainer(limit_train_batches=100, max_epochs=max_epochs)\n",
    "trainer.fit(model=net, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.650895Z",
     "start_time": "2023-05-20T01:57:03.650889Z"
    }
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T06:21:46.356828Z",
     "start_time": "2023-05-14T06:21:46.351801Z"
    }
   },
   "source": [
    "# Read hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.651740Z",
     "start_time": "2023-05-20T01:57:03.651734Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pytorch_lightning as pl\n",
    "from lightning.pytorch.loggers.csv_logs import CSVLogger\n",
    "# from pytorch_lightning.loggers.csv_logs import CSVLogger as CSVLogger2\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def read_metrics_csv(metrics_file_path):\n",
    "    df_hist = pd.read_csv(metrics_file_path)\n",
    "    df_hist[\"epoch\"] = df_hist[\"epoch\"].ffill()\n",
    "    df_histe = df_hist.set_index(\"epoch\").groupby(\"epoch\").mean()\n",
    "    return df_histe\n",
    "\n",
    "\n",
    "def read_hist(trainer: pl.Trainer):\n",
    "\n",
    "    ts = [t for t in trainer.loggers if isinstance(t, CSVLogger)]\n",
    "    print(ts)\n",
    "    try:\n",
    "        metrics_file_path = Path(ts[0].experiment.metrics_file_path)\n",
    "        df_histe = read_metrics_csv(metrics_file_path)\n",
    "        return df_histe\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.652269Z",
     "start_time": "2023-05-20T01:57:03.652263Z"
    }
   },
   "outputs": [],
   "source": [
    "df_hist = read_hist(trainer).ffill().bfill()\n",
    "df_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T01:57:03.653040Z",
     "start_time": "2023-05-20T01:57:03.653033Z"
    }
   },
   "outputs": [],
   "source": [
    "df_hist[['val/acc', 'train/acc']].plot()\n",
    "\n",
    "df_hist[['val/f1', 'train/f1']].plot()\n",
    "\n",
    "df_hist[['val/loss', 'train/loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlk2",
   "language": "python",
   "name": "dlk2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "b80286374679f2ad472c61c83fc267d31329b5dea8e2dcaccb727123767724c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
