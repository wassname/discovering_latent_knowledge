{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pipelines as this https://github.com/wassname/representation-engineering/blob/random_comments_ignore/examples/honesty/honesty.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/elk/discovering_latent_knowledge/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import your package\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from loguru import logger\n",
    "logger.add(os.sys.stderr, format=\"{time} {level} {message}\", level=\"INFO\")\n",
    "\n",
    "from typing import Optional, List, Dict, Union, Tuple, Callable, Iterable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM\n",
    "from src.repe import repe_pipeline_registry\n",
    "repe_pipeline_registry()\n",
    "\n",
    "from src.models.load import load_model\n",
    "from src.extraction.config import ExtractConfig\n",
    "from src.prompts.prompt_loading import load_preproc_dataset\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "# from sklearn.preprocessing import RobustScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtractConfig(datasets=('amazon_polarity', 'super_glue:boolq', 'glue:qnli', 'imdb'), model='TheBloke/WizardCoder-Python-13B-V1.0-GPTQ', data_dirs=(), max_examples=(100, 100), num_shots=1, num_variants=-1, layers=(), seed=42, template_path=None, max_length=666)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-25 13:32:38.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.load\u001b[0m:\u001b[36mverbose_change_param\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mchanging pad_token_id from 32000 to 0\u001b[0m\n",
      "2023-10-25T13:32:38.035153+0800 INFO changing pad_token_id from 32000 to 0\n",
      "\u001b[32m2023-10-25 13:32:38.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.load\u001b[0m:\u001b[36mverbose_change_param\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mchanging padding_side from right to left\u001b[0m\n",
      "2023-10-25T13:32:38.036448+0800 INFO changing padding_side from right to left\n",
      "\u001b[32m2023-10-25 13:32:38.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.load\u001b[0m:\u001b[36mverbose_change_param\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mchanging truncation_side from right to left\u001b[0m\n",
      "2023-10-25T13:32:38.037328+0800 INFO changing truncation_side from right to left\n"
     ]
    }
   ],
   "source": [
    "# model_name_or_path = \"TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ\"\n",
    "# model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.1-GPTQ\"\n",
    "model_name_or_path = \"TheBloke/WizardCoder-Python-13B-V1.0-GPTQ\"\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "cfg = ExtractConfig(max_examples=(100, 100), model=model_name_or_path, max_length=666)\n",
    "print(cfg)\n",
    "\n",
    "model, tokenizer = load_model(model_name_or_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# hidden_layers = list(range(-1, -model.config.num_hidden_layers, -1))\n",
    "# hidden_layers = [f\"model.layers.{i}\" for i in range(8, model.config.num_hidden_layers, 3)]\n",
    "# hidden_layers = list(range(8, model.config.num_hidden_layers, 3))\n",
    "# hidden_layers\n",
    "\n",
    "\n",
    "\n",
    "# rep_reading_pipeline =  pipeline(\"rep-reading\", model=model, tokenizer=tokenizer)\n",
    "# rep_reading_pipeline\n",
    "# hidden_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cache busting for the transformers map and ds steps\n",
    "!rm -rf ~/.cache/huggingface/datasets/generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervention fit/load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from src.config import root_folder\n",
    "tokenizer_args=dict(padding=\"max_length\", max_length=cfg.max_length, truncation=True, add_special_tokens=True)\n",
    "            \n",
    "def load_rep_reader(model, tokenizer, cfg, N_fit_examples=20, batch_size=2, rep_token = -1, n_difference = 1, direction_method = 'pca'):\n",
    "    \"\"\"\n",
    "    We want one set of interventions per model\n",
    "    \n",
    "    So we always load a cached version if possible. to make it approx repeatable use the same dataset etc\n",
    "    \"\"\"\n",
    "    model_name = cfg.model.replace('/', '-')\n",
    "    intervention_f = root_folder / 'data' / 'interventions' / f'{model_name}.pkl'\n",
    "    intervention_f.parent.mkdir(exist_ok=True, parents=True)\n",
    "    if not intervention_f.exists():        \n",
    "        \n",
    "        hidden_layers = list(range(8, model.config.num_hidden_layers, 3))\n",
    "        \n",
    "        dataset_fit = load_preproc_dataset('imdb', cfg, tokenizer, N=N_fit_examples)\n",
    "        \n",
    "        rep_reading_pipeline =  pipeline(\"rep-reading\", model=model, tokenizer=tokenizer)\n",
    "        honesty_rep_reader = rep_reading_pipeline.get_directions(\n",
    "            dataset_fit['question'], \n",
    "            rep_token=rep_token, \n",
    "            hidden_layers=hidden_layers, \n",
    "            n_difference=n_difference, \n",
    "            train_labels=dataset_fit['label_true'], \n",
    "            direction_method=direction_method,\n",
    "            batch_size=batch_size,\n",
    "            **tokenizer_args\n",
    "        )\n",
    "        # and save\n",
    "        with open(intervention_f, 'wb') as f:\n",
    "            pickle.dump(honesty_rep_reader, f)\n",
    "            logger.info(f'Saved interventions to {intervention_f}')\n",
    "    else:\n",
    "        with open(intervention_f, 'rb') as f:\n",
    "            honesty_rep_reader = pickle.load(f)\n",
    "        logger.info(f'Loaded interventions from {intervention_f}')\n",
    "            \n",
    "    return honesty_rep_reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-25 13:32:42.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_rep_reader\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mLoaded interventions from /media/wassname/SGIronWolf/projects5/elk/discovering_latent_knowledge/data/interventions/TheBloke-WizardCoder-Python-13B-V1.0-GPTQ.pkl\u001b[0m\n",
      "2023-10-25T13:32:42.237595+0800 INFO Loaded interventions from /media/wassname/SGIronWolf/projects5/elk/discovering_latent_knowledge/data/interventions/TheBloke-WizardCoder-Python-13B-V1.0-GPTQ.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# N_fit_examples = 20\n",
    "N_fit_examples = 10\n",
    "rep_token = -1\n",
    "\n",
    "honesty_rep_reader = load_rep_reader(model, tokenizer, cfg, N_fit_examples=N_fit_examples, batch_size=batch_size, rep_token=rep_token)\n",
    "\n",
    "hidden_layers = sorted(honesty_rep_reader.directions.keys())\n",
    "hidden_layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 0 examples [00:00, ? examples/s]"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "ds_name = 'imdb'\n",
    "ds_tokens = load_preproc_dataset(ds_name, cfg, tokenizer)\n",
    "ds_tokens\n",
    "\n",
    "\n",
    "N_train_split = (len(ds_tokens) - N_fit_examples) //2\n",
    "\n",
    "# split the dataset, it's preshuffled\n",
    "dataset_fit = ds_tokens.select(range(N_fit_examples))\n",
    "dataset_train = ds_tokens.select(range(N_fit_examples, N_train_split))\n",
    "dataset_test = ds_tokens.select(range(N_train_split, len(ds_tokens)))\n",
    "dataset_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit\n",
    "# # FIXME: load or save here if the inputs are the same....\n",
    "# train_labels = dataset_fit['label_true']\n",
    "# honesty_rep_reader = rep_reading_pipeline.get_directions(\n",
    "#     dataset_fit['question'], \n",
    "#     rep_token=rep_token, \n",
    "#     hidden_layers=hidden_layers, \n",
    "#     n_difference=n_difference, \n",
    "#     train_labels=dataset_fit['label_true'], \n",
    "#     direction_method=direction_method,\n",
    "#     batch_size=batch_size,\n",
    "#     **tokenizer_args\n",
    "# )\n",
    "# honesty_rep_reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_reading_pipeline =  pipeline(\"rep-reading\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read direction for each example, layer\n",
    "H_tests = rep_reading_pipeline(\n",
    "    dataset_train['question'], \n",
    "    rep_token=rep_token, \n",
    "    hidden_layers=hidden_layers, \n",
    "    rep_reader=honesty_rep_reader,\n",
    "    batch_size=batch_size, **tokenizer_args)\n",
    "\n",
    "H_tests[0] # {Batch, layers}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dataset_train[:3]\n",
    "inputs['question']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(control_outputs_neg, baseline_outputs, control_outputs):\n",
    "    signs = [-1, 0, 1]\n",
    "    for i in range(len(baseline_outputs['ans'])):\n",
    "        ranked = []\n",
    "        for j, r in enumerate([control_outputs_neg, baseline_outputs, control_outputs]):        \n",
    "            choices = r['answer_choices'][i]\n",
    "            label = r['label_true'][i]\n",
    "            ans = r['ans'][i].item()\n",
    "            sign = signs[j]\n",
    "            ranked.append(ans)\n",
    "            choice_true = choices[label]\n",
    "            if label==0:\n",
    "                ans *= -1            \n",
    "            print(f\"==== Control ({signs[j]}) ====\")\n",
    "            print(f\"Score: {ans:02.2%} of true ans `{choice_true}`\")\n",
    "            # print(f\"Text ans: {r['text_ans'][i]}\") \n",
    "        \n",
    "        is_ranked = (np.argsort(ranked)==np.arange(3)).all()\n",
    "        print(f\"Ranked? {is_ranked} {ranked}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rep_control_pipeline2 = pipeline(\n",
    "    \"rep-control2\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    layers=hidden_layers, \n",
    "    max_length=cfg.max_length,)\n",
    "rep_control_pipeline2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coeff=8.0\n",
    "max_new_tokens=1\n",
    "\n",
    "activations = {}\n",
    "for layer in hidden_layers:\n",
    "    activations[layer] = torch.tensor(coeff * honesty_rep_reader.directions[layer] * honesty_rep_reader.direction_signs[layer]).to(model.device).half()\n",
    "    \n",
    "\n",
    "activations_neg = {k:-v for k,v in activations.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test: with multiple input types: single, list, generator, dataset\n",
    "## single\n",
    "input_types = {'single':dataset_train[0], 'list':dataset_train[:5], 'generator':iter(dataset_train.select(range(5))), 'dataset':dataset_train.select(range(5)).to_iterable_dataset()}\n",
    "for name, ds in input_types.items():\n",
    "    print(f\"==== {name} ====\")\n",
    "    control_outputs = rep_control_pipeline2(ds, activations=activations, batch_size=2)\n",
    "    r = list(control_outputs)\n",
    "    print(len(r))\n",
    "\n",
    "\n",
    "\n",
    "# control_outputs = rep_control_pipeline2(dataset_train[0], activations=activations)\n",
    "# list(control_outputs)\n",
    "\n",
    "# ## list\n",
    "# control_outputs = rep_control_pipeline2(dataset_train[:5], activations=activations, batch_size=2)\n",
    "# list(control_outputs)\n",
    "\n",
    "# # generator\n",
    "# ds = iter(dataset_train.select(range(5)))\n",
    "# control_outputs = rep_control_pipeline2(ds, activations=activations, batch_size=2)\n",
    "# list(control_outputs)\n",
    "\n",
    "# # dataset\n",
    "# ds = dataset_train.select(range(5)).to_iterable_dataset()\n",
    "# control_outputs = rep_control_pipeline2(ds, activations=activations, batch_size=2)\n",
    "# list(control_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    baseline_outputs = rep_control_pipeline2(inputs, batch_size=batch_size)\n",
    "    control_outputs = rep_control_pipeline2(inputs, activations=activations, batch_size=batch_size)\n",
    "    control_outputs_neg = rep_control_pipeline2(inputs, activations=activations_neg, batch_size=batch_size)\n",
    "\n",
    "\n",
    "metrics(control_outputs_neg, baseline_outputs, control_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# from datasets import Dataset, DatasetInfo\n",
    "import datasets\n",
    "from src.config import root_folder\n",
    "from pathvalidate import sanitize_filename\n",
    "from src.helpers.ds import ds_keep_cols\n",
    "\n",
    "def create_hs_ds(ds_name, ds_tokens, pipeline, activations=None, f = None, batch_size=2, split_type=\"train\", debug=False):\n",
    "    \"create a dataset of hidden states.\"\"\"\n",
    "    \n",
    "    N = len(ds_tokens)\n",
    "    dataset_name = sanitize_filename(f\"{cfg.model}_{ds_name}_{split_type}_{N}\", replacement_text=\"_\")\n",
    "    f = str(root_folder / '.ds'/ f\"{dataset_name}\")\n",
    "    \n",
    "    info_kwargs = dict(extract_cfg=cfg.to_dict(), ds_name=ds_name, split_type=split_type, f=f, date=pd.Timestamp.now().isoformat(),)\n",
    "    \n",
    "    torch_cols = ['input_ids', 'attention_mask', 'choice_ids', 'question', 'answer_choices', 'example_i', 'label_true', 'sys_instr_name', 'template_name', 'instructed_to_lie']\n",
    "    ds_t_subset = ds_keep_cols(ds_tokens, torch_cols)\n",
    "    ds = ds_t_subset.to_iterable_dataset()\n",
    "    # pipeline_it = rep_control_pipeline2(ds, batch_size=batch_size, **text_gen_kwargs)\n",
    "    \n",
    "    # first we make the calibration dataset with no intervention\n",
    "    gen_kwargs = dict(\n",
    "        model_inputs=ds,\n",
    "        activations=activations,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    \n",
    "    if debug:\n",
    "        # this allow us to debug in a single thread\n",
    "        pipeline(**gen_kwargs)\n",
    "    \n",
    "    ds1 = datasets.Dataset.from_generator(\n",
    "        generator=pipeline,\n",
    "        info=datasets.DatasetInfo(\n",
    "            description=json.dumps(info_kwargs, indent=2),\n",
    "            config_name=f,\n",
    "        ),\n",
    "        gen_kwargs=gen_kwargs,\n",
    "        num_proc=1,\n",
    "    )\n",
    "    logger.info(f\"Created dataset {dataset_name} with {len(ds1)} examples at `{f}`\")\n",
    "    return ds1, f# TODO we need to save and cache for many split and datasets\n",
    "rep_control_pipeline2\n",
    "\n",
    "\n",
    "\n",
    "ds1, f = create_hs_ds('imdb', dataset_train, rep_control_pipeline2, split_type=\"train\", debug=True)\n",
    "ds1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train['answer_choices'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "ds = dataset_train.to_iterable_dataset()\n",
    "next(iter(ds))['answer_choices']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
