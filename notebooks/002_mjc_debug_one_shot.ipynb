{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook to quickly iterate and make sure the llama models are loading and working OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM, AutoModelForCausalLM, LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "from transformers import GenerationConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_repo = \"decapoda-research/llama-7b-hf\"\n",
    "model_repo = \"Neko-Institute-of-Science/LLaMA-7B-HF\"\n",
    "model_repo = \"elinas/llama-13b-hf-transformers-4.29\"\n",
    "\n",
    "# lora_repo = \"tloen/alpaca-lora-7b\"\n",
    "lora_repo = \"NousResearch/gpt4-x-vicuna-13b\"\n",
    "\n",
    "# model_repo = \"TheBloke/wizardLM-7B-HF\"\n",
    "# lora_repo = None\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_repo, device_map=\"auto\", \n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16)\n",
    "# if lora_repo is not None:\n",
    "#     # https://github.com/tloen/alpaca-lora/blob/main/generate.py#L40\n",
    "#     from peft import PeftModel\n",
    "#     model = PeftModel.from_pretrained(\n",
    "#         model, \n",
    "#         lora_repo, \n",
    "#         torch_dtype=torch.float16,\n",
    "#         device_map='auto'#{'': 0}\n",
    "#     )\n",
    "tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_imdb(text, label):\n",
    "    return f\"\"\"Review: \"I think this is a lovely family movie. There are plenty of hilarious scenes and heart-warming moments to be had throughout the movie. The actors are great and the effects well executed throughout. Danny Glover plays George Knox who manages the terrible baseball team 'The Angels' and is great throughout the film. Also fantastic are the young actors Joseph Gordon-Levitt and Milton Davis Jr. Christopher Lloyd is good as Al 'The Angel' and the effects are great in this top notch Disney movie. A touching and heart-warming movie which everyone should enjoy.\"\n",
    "Question: Is this review positive? \n",
    "Answer: 1\n",
    "---\n",
    "Review: \" Although Hypnotic isn't without glimmers of inspiration, the ultimate effect of this often clunky crime caper will be to leave you feeling rather sleepy.\"\n",
    "Question: Is this review positive?\n",
    "Answer: 0\n",
    "---\n",
    "Review: \"A galactic group hug that might squeeze a little too tight on the heartstrings, the final Guardians of the Galaxy is a loving last hurrah for the MCU's most ragtag family.\"\n",
    "Question: Is this review negative?\n",
    "Answer: 0\n",
    "---\n",
    "Review: \"{text}\"\n",
    "Question: Is this review {'positive' if label else 'negative'}?\n",
    "Answer: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/deep-diver/LLM-As-Chatbot/blob/main/configs/response_configs/default.yaml\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0.95,\n",
    "    top_p=0.9,\n",
    "    top_k=50,\n",
    "    num_beams=1,\n",
    "    use_cache=True,\n",
    "    repetition_penalty=1.2,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    ")\n",
    "\n",
    "input_text = format_imdb(\"The room is the worst movie ever\", 0)\n",
    "# print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://github.com/deep-diver/LLM-As-Chatbot/blob/216abb559d00a0555f41a1426ac9db6c1abc24f3/gens/batch_gen.py#L3\n",
    "input_ids = tokenizer(input_text, \n",
    "                          return_tensors=\"pt\",\n",
    "#                           truncation=True, \n",
    "#                           padding=True,\n",
    "#                           max_length=600,\n",
    "                        #   add_special_tokens=False,\n",
    "                         ).input_ids.to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generation_output = model.generate(\n",
    "        input_ids=input_ids, generation_config=generation_config,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            # max_new_tokens=max_new_tokens,\n",
    "    )\n",
    "\n",
    "s = generation_output.sequences[0]\n",
    "torch.cuda.empty_cache()    \n",
    "# text_q = tokenizer.batch_decode(input_ids, \n",
    "#                                 skip_prompt=True, skip_special_tokens=True\n",
    "#                                 )\n",
    "text_ans = tokenizer.decode(s,\n",
    "                                  #skip_prompt=True, skip_special_tokens=True\n",
    "                                  )\n",
    "# print(text_q[0])\n",
    "print('='*40+'answ'+'='*40)\n",
    "print(text_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ans = tokenizer.decode(s,\n",
    "                                #   skip_prompt=True, \n",
    "                                #   skip_special_tokens=True\n",
    "                                  )\n",
    "print(text_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlk2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
