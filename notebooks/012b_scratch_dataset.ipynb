{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload import your package\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from make_dataset import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtractConfig(datasets=('amazon_polarity', 'super_glue:boolq', 'glue:qnli', 'imdb'), model='TheBloke/WizardCoder-Python-13B-V1.0-GPTQ', data_dirs=(), max_examples=(10, 10), num_shots=1, num_variants=-1, layers=(), seed=42, token_loc='last', template_path=None, max_length=999)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = ExtractConfig(max_examples=(10, 10), max_length=999)\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-15 16:46:07.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.load\u001b[0m:\u001b[36mverbose_change_param\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mchanging pad_token_id from 32000 to 0\u001b[0m\n",
      "\u001b[32m2023-10-15 16:46:07.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.load\u001b[0m:\u001b[36mverbose_change_param\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mchanging padding_side from right to left\u001b[0m\n",
      "\u001b[32m2023-10-15 16:46:07.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.load\u001b[0m:\u001b[36mverbose_change_param\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mchanging truncation_side from right to left\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model(cfg.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d937549193694407bccbe69577fc057e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenize:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11563ae0472e4215982ba483b7710715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "truncated:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b24eb7b7cfa42c1840a7676cbe1f942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "prompt_truncated:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3174bc1f2a034d5ab09d37549858ecc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "choice_ids:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa208807eea47bdb460d3120b9f3953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed truncated rows to leave: num_rows 10\n"
     ]
    }
   ],
   "source": [
    "ds_name = cfg.datasets[0]\n",
    "split_type = \"train\"\n",
    "ds_tokens = load_preproc_dataset(ds_name, cfg, tokenizer)\n",
    "\n",
    "ds_tokens_calibration = ds_tokens.select(range(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = next(iter(ds_tokens))\n",
    "# b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the calibration dataset\n",
    "BATCH_SIZE = 2\n",
    "f = None\n",
    "info_kwargs = dict(extract_cfg=cfg.to_dict(), ds_name=ds_name, split_type=split_type, f=f, date=pd.Timestamp.now().isoformat(),)\n",
    "intervention_dicts = [None, ]\n",
    "gen_kwargs = dict(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data=ds_tokens,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    layer_padding=cfg.layer_padding,\n",
    "    layer_stride=cfg.layer_stride,\n",
    "    intervention_dicts=intervention_dicts,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f092c8b927474979a94c3357505e4c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfbe70a3653465da59ca5e945bce2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get hidden states:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['scores0', 'ds_index', 'scores', 'head_activation', 'ds_string', 'example_i', 'answer', 'question', 'answer_choices', 'template_name', 'label_true', 'label_instructed', 'instructed_to_lie', 'sys_instr_name', 'truncated', 'prompt_truncated'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1 = Dataset.from_generator(\n",
    "    generator=batch_hidden_states,\n",
    "    info=DatasetInfo(\n",
    "        description=json.dumps(info_kwargs, indent=2),\n",
    "        config_name=f,\n",
    "    ),\n",
    "    gen_kwargs=gen_kwargs,\n",
    "    num_proc=1,\n",
    ")\n",
    "ds1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtractHiddenStates(model=LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32001, 5120, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "          (k_proj): QuantLinear()\n",
       "          (o_proj): QuantLinear()\n",
       "          (q_proj): QuantLinear()\n",
       "          (v_proj): QuantLinear()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (act_fn): SiLUActivation()\n",
       "          (down_proj): QuantLinear()\n",
       "          (gate_proj): QuantLinear()\n",
       "          (up_proj): QuantLinear()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=32001, bias=False)\n",
       "), tokenizer=LlamaTokenizerFast(name_or_path='TheBloke/WizardCoder-Python-13B-V1.0-GPTQ', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='left', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False), intervention_dicts=[None], layer_stride=4, layer_padding=4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.datasets.hs import ExtractHiddenStates\n",
    "ehs = ExtractHiddenStates(model, tokenizer, intervention_dicts=intervention_dicts, layer_stride=cfg.layer_stride, layer_padding=cfg.layer_padding)\n",
    "ehs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f49fdcc67b4496fbdd136c8b10dd024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get hidden states:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = BATCH_SIZE\n",
    "data = ds_tokens_calibration\n",
    "from src.helpers.ds import ds_keep_cols, clear_mem\n",
    "\n",
    "# get a batch\n",
    "torch_cols = ['input_ids', 'attention_mask', 'choice_ids']\n",
    "ds_t_subset = ds_keep_cols(data, torch_cols)\n",
    "ds_t_subset.set_format(type='torch')\n",
    "\n",
    "ds_p_subset = data.remove_columns(torch_cols)\n",
    "dl = DataLoader(ds_t_subset, batch_size=batch_size, shuffle=False)\n",
    "for i, batch in enumerate(tqdm(dl, desc='get hidden states')):\n",
    "    input_ids, attention_mask, choice_ids =  batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"choice_ids\"]\n",
    "    \n",
    "#     nn = len(input_ids)\n",
    "#     index = i*batch_size+np.arange(nn)\n",
    "    \n",
    "#     # different due to dropout\n",
    "#     hsl = ehs.get_batch_of_hidden_states(input_ids=input_ids, attention_mask=attention_mask, choice_ids=choice_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.datasets.intervene import get_com_directions, get_interventions_dict\n",
    "# head_wise_activations = np.array(ds1['head_activation'])\n",
    "# labels=np.array(ds1[\"label_true\"])\n",
    "# get_com_directions(2, \n",
    "#                    2, \n",
    "#                    head_wise_activations, \n",
    "#                    labels\n",
    "#                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, reduce, repeat, asnumpy, parse_shape\n",
    "from src.datasets.intervene import InterventionDict\n",
    "from typing import Tuple\n",
    "\n",
    "activations = np.array(ds1['head_activation']).squeeze(-1)\n",
    "labels = np.array(ds1[\"label_true\"]).astype(int)==1\n",
    "num_heads = model.config.num_attention_heads\n",
    "\n",
    "layer_names = [f\"model.layers.{i}.self_attn\" for i in range(model.config.num_hidden_layers)]\n",
    "layer_names, layer_inds = ehs.get_layer_selection(layer_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.4062, 12.5859,  0.4016,  ..., -2.1797, -1.2871, -2.1543],\n",
       "         [-3.4082, 12.5625,  0.3992,  ..., -2.1777, -1.2900, -2.1543],\n",
       "         [-3.4062, 12.5703,  0.3999,  ..., -2.1777, -1.2910, -2.1543],\n",
       "         ...,\n",
       "         [-2.4629,  0.2039, 12.3828,  ..., -2.2266,  0.8071,  0.2996],\n",
       "         [-6.0508, -6.7305, 10.3047,  ..., -4.7031, -2.3340, -2.0586],\n",
       "         [-7.2188, -8.3750,  9.3047,  ..., -5.4141, -2.8828, -3.3223]],\n",
       "\n",
       "        [[-3.4004, 12.8203,  0.4661,  ..., -2.1914, -1.1826, -2.1445],\n",
       "         [-3.4023, 12.7891,  0.4626,  ..., -2.1914, -1.1885, -2.1465],\n",
       "         [-3.4004, 12.7969,  0.4636,  ..., -2.1914, -1.1865, -2.1445],\n",
       "         ...,\n",
       "         [-1.5488,  0.2537, 10.4453,  ..., -1.8154,  0.9443,  0.6328],\n",
       "         [-6.2344, -7.9570,  7.3828,  ..., -4.1797, -3.3203, -2.4883],\n",
       "         [-5.7266, -7.7461, 10.3828,  ..., -3.4277, -2.1797, -2.3887]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "from baukit.nethook import Trace, TraceDict, recursive_copy\n",
    "from src.datasets.intervene import intervention_meta_fn, get_interventions_dict\n",
    "\n",
    "interventions = get_interventions_dict(activations, labels, layer_names, num_heads)\n",
    "intervention_fn = partial(intervention_meta_fn, interventions=interventions, num_heads=num_heads)\n",
    "model.cuda().eval()\n",
    "\n",
    "device = model.device\n",
    "with torch.no_grad():\n",
    "    with TraceDict(model, layer_names, edit_output=intervention_fn) as ret:\n",
    "        outputs = model(input_ids=input_ids.to(device), attention_mask=attention_mask.to(device), return_dict=True, output_hidden_states=True)\n",
    "        a = outputs[0]\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.4043, 12.5703,  0.4009,  ..., -2.1777, -1.2881, -2.1523],\n",
       "         [-3.4043, 12.5781,  0.4006,  ..., -2.1758, -1.2881, -2.1523],\n",
       "         [-3.4043, 12.5703,  0.4006,  ..., -2.1777, -1.2900, -2.1543],\n",
       "         ...,\n",
       "         [-2.4629,  0.2039, 12.3828,  ..., -2.2266,  0.8071,  0.2996],\n",
       "         [-6.0508, -6.7305, 10.3047,  ..., -4.7031, -2.3340, -2.0586],\n",
       "         [-6.3906, -7.0547,  8.7266,  ..., -4.8984, -2.3691, -2.8887]],\n",
       "\n",
       "        [[-3.4023, 12.8203,  0.4658,  ..., -2.1934, -1.1855, -2.1445],\n",
       "         [-3.4023, 12.7891,  0.4644,  ..., -2.1914, -1.1875, -2.1445],\n",
       "         [-3.4023, 12.8125,  0.4648,  ..., -2.1934, -1.1865, -2.1445],\n",
       "         ...,\n",
       "         [-1.5488,  0.2537, 10.4453,  ..., -1.8154,  0.9443,  0.6328],\n",
       "         [-6.2344, -7.9570,  7.3828,  ..., -4.1797, -3.3203, -2.4883],\n",
       "         [-4.9375, -6.7891,  9.5312,  ..., -3.1250, -1.7793, -1.9893]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    with TraceDict(model, layer_names) as ret:\n",
    "        outputs = model(input_ids=input_ids.to(device), attention_mask=attention_mask.to(device), return_dict=True, output_hidden_states=True)\n",
    "        a = outputs[0]\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.4062, 12.5859,  0.4014,  ..., -2.1797, -1.2881, -2.1543],\n",
       "         [-3.4082, 12.5859,  0.4011,  ..., -2.1797, -1.2881, -2.1562],\n",
       "         [-3.4062, 12.5703,  0.3999,  ..., -2.1777, -1.2910, -2.1543],\n",
       "         ...,\n",
       "         [-2.4629,  0.2039, 12.3828,  ..., -2.2266,  0.8071,  0.2996],\n",
       "         [-6.0508, -6.7305, 10.3047,  ..., -4.7031, -2.3340, -2.0586],\n",
       "         [-5.8555, -6.3125,  7.6172,  ..., -4.5625, -2.0273, -2.6055]],\n",
       "\n",
       "        [[-3.4023, 12.8125,  0.4661,  ..., -2.1953, -1.1846, -2.1445],\n",
       "         [-3.4023, 12.7891,  0.4639,  ..., -2.1914, -1.1885, -2.1445],\n",
       "         [-3.4004, 12.7969,  0.4629,  ..., -2.1895, -1.1885, -2.1445],\n",
       "         ...,\n",
       "         [-1.5488,  0.2537, 10.4453,  ..., -1.8154,  0.9443,  0.6328],\n",
       "         [-6.2344, -7.9570,  7.3828,  ..., -4.1797, -3.3203, -2.4883],\n",
       "         [-4.5547, -6.3555,  7.9883,  ..., -3.1680, -1.6172, -1.8477]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervention_fn2 = partial(intervention_meta_fn, interventions=interventions, num_heads=num_heads, alpha=-15)\n",
    "model.cuda().eval()\n",
    "\n",
    "device = model.device\n",
    "with torch.no_grad():\n",
    "    with TraceDict(model, layer_names, edit_output=intervention_fn2) as ret:\n",
    "        outputs = model(input_ids=input_ids.to(device), attention_mask=attention_mask.to(device), return_dict=True, output_hidden_states=True)\n",
    "        a = outputs[0]\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlk4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
